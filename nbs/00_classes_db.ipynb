{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and create the SQLite database\n",
    "\n",
    "> This module defines the classes we use to represent the PKM workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp classdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import List, Union, ClassVar\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, field_serializer, field_validator\n",
    "from fastlite import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `from __future__ import annotations` to support forward references in type hints. To be precise in the `@classmethod` we create to keep track of all instances of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the possible values of the different variables that are available in the classes. We use the module `enum` to define **Enumerations**. We use this to bind the possible values to a variable name, making the code more readable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationType(Enum):\n",
    "    \"\"\"Information content types that flow through the PKM workflow.\"\"\"\n",
    "    BOOK = \"book\"\n",
    "    RESEARCH_PAPER = \"research_paper\"\n",
    "    DOCUMENT = \"document\"\n",
    "    ANNOTATION = \"annotations&highlights\"\n",
    "    NOTE = \"note\"\n",
    "    EMAIL = \"email\"\n",
    "    DISCORD_MESSAGE = \"discord_message\"\n",
    "    WEB_ARTICLE = \"web_article\"\n",
    "    YOUTUBE_VIDEO = \"youtube_video\"\n",
    "    PODCAST = \"podcast\"\n",
    "    PRODUCT_IDEA = \"product_idea\"\n",
    "    PROJECT_IDEA = \"project_idea\"\n",
    "\n",
    "class Method(Enum):\n",
    "    \"\"\"How actions are performed - manually or automatically.\"\"\"\n",
    "    MANUAL = \"manual\"\n",
    "    AUTOMATIC = \"automatic\"\n",
    "\n",
    "class Phase(Enum):\n",
    "    \"\"\"The five phases of the PKM workflow.\"\"\"\n",
    "    COLLECT = \"collect\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    CONSUME = \"consume\"\n",
    "    EXTRACT = \"extract\"\n",
    "    REFINE = \"refine\"\n",
    "\n",
    "class PhaseQuality(Enum):\n",
    "    \"\"\"Quality rating for how well a tool performs in each phase.\"\"\"\n",
    "    NA = \"na\"\n",
    "    BAD = \"bad\"\n",
    "    OK = \"ok\"\n",
    "    GREAT = \"great\"\n",
    "\n",
    "class OrganizationSystem(Enum):\n",
    "    \"\"\"How tools organize and structure information.\"\"\"\n",
    "    TAGS = \"tags\"\n",
    "    FOLDERS = \"folders\"\n",
    "    LINKS = \"links\"\n",
    "    JOHNNY_DECIMAL = \"johnny_decimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Phase.REFINE: 'refine'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phase(\"refine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKM Workflow Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a dataclass for each item we need to be present in the PKM workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track instances of classes\n",
    "\n",
    "We also want to keep track of the instances available for each class. Therefore we need some higher order magic.\n",
    "\n",
    "- a list in the class to store the instances\n",
    "- a __init__ method to add the instance to the list\n",
    "- a classmethod to get the list of instances\n",
    "\n",
    "We can't just add a `_instances = []` statement to the Class, because Pydantic will then assume it is a model field (private attribute). We need to tell Pydantic to ignore the _instances class variable as a model field and treat is as a class variable. Therefore we need to import `ClassVar` from `typing` and use it to type the _instances variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pydantic with MiniDataAPI and SQLite\n",
    "\n",
    "We want to use `Pydantic` Dataclasses to enable typechecking and validation. We also want to use the Dataclasses with the `MiniDataAPI` to create the tables in the `SQLite` database. But `SQLite` only has datatypes: `NULL`, `INTEGER`, `REAL`, `TEXT`, and `BLOB`. So no `list` or any of the Dataclass(Enum) types we use.\n",
    "\n",
    "To be able to use both `Pydanctic` and the `MiniDataAPI` we will do two things:\n",
    "\n",
    "1. Define a Pydantic Dataclass with the correct datatypes and a Dataclass that has the same fields as the Pydantic Dataclass, but with datatypes that can be used with SQLite.\n",
    "2. We add `@field_serializer` and `@field_validator` methods to the Pydantic Dataclass that convert the fields to JSON strings when we use the method `.model_dump()` on the instance of the Pydantic Dataclass.\n",
    "\n",
    "This way we can:\n",
    "\n",
    "- create the SQLite database tables using the regular Dataclasses.\n",
    "- create instances with the Pydantic Dataclass to have easy typechecking and validation.\n",
    "- convert this instances to `MiniDataAPI` and `SQLite` friendly datatypes using `.model_dump()` on the instance.\n",
    "\n",
    "```python\n",
    "class InformationItem(BaseModel):\n",
    "    info_type: InformationType\n",
    "    method: List[Union[Method, None]]\n",
    "    toolflow: List[str]\n",
    "    \n",
    "    # Convert Enum to string and list to JSON string so we can add to SQLite\n",
    "    @field_serializer('info_type', 'method', 'toolflow')\n",
    "    def serialize_lists(self, v):\n",
    "        if isintance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else str(v)\n",
    "    \n",
    "    # Convert JSON string from SQLite to list of Enum and strings\n",
    "    @field_validator('method', 'toolflow', mode='before')\n",
    "    def parse_json_lists(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return json.loads(v)\n",
    "        return v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pydantic Dataclasses**\n",
    "\n",
    "Used for typechecking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationItem(BaseModel):\n",
    "    \"\"\"Represents an information item flowing through the PKM workflow.\"\"\"\n",
    "    name: str\n",
    "    info_type: InformationType\n",
    "    method: list[Union[Method, None]]  # [collect, retrieve, consume, extract, refine]\n",
    "    toolflow: list  # [collect, retrieve, consume, extract, refine]\n",
    "\n",
    "    _instances: ClassVar[list[InformationItem]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> List[InformationItem]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('info_type','method', 'toolflow')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('method', 'toolflow', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    \"\"\"Represents a PKM tool with supported information items.\"\"\"\n",
    "    name: str\n",
    "    info_items: list[InformationItem]\n",
    "    organization_system: list[OrganizationSystem]\n",
    "    phase_quality: list[PhaseQuality]\n",
    "\n",
    "    _instances: ClassVar[List[Tool]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> list[Tool]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('info_items', 'organization_system', 'phase_quality')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('info_items', 'organization_system', 'phase_quality', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value\n",
    "\n",
    "class Improvement(BaseModel):\n",
    "    \"\"\"Tracks workflow improvements needed for better PKM effectiveness.\"\"\"\n",
    "    title: str\n",
    "    what: str\n",
    "    why: str\n",
    "    prio: int\n",
    "    tool: Tool\n",
    "    phase: Phase\n",
    "\n",
    "    _instances: ClassVar[List[Improvement]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> list[Improvement]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('tool', 'phase')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('tool', 'phase', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test creating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_a = InformationItem(name=\"infoitem_a\", info_type=InformationType.BOOK, method=[Method.MANUAL], toolflow=[Phase.COLLECT])\n",
    "tool_a = Tool(name=\"reader\", info_items=[inf_a], organization_system=[OrganizationSystem.TAGS], phase_quality=[PhaseQuality.GREAT])\n",
    "imp_a = Improvement(title=\"improvement_a\", what=\"gras\", why=\"dus\", prio=0, tool=tool_a, phase=Phase.COLLECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test creating list of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(Improvement.get_instances()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular Dataclasses with SQLite datatypes**\n",
    "\n",
    "Used for creating the tables in the SQLite database.\n",
    "These contain the same fields as the Pydantic Dataclasses we defined above. But these Dataclasses only contain datatypes that are supported by SQLite and have an `id: int` field added as a primary key and use the build-in `@dataclass` decorator, because `FastLite` doesn't support Pydantic Dataclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ImprovementDB:\n",
    "    id: int\n",
    "    title: str\n",
    "    what: str\n",
    "    why: str\n",
    "    prio: int\n",
    "    workflow_routes: str\n",
    "\n",
    "@dataclass\n",
    "class InformationItemDB:\n",
    "    id: int\n",
    "    name: str\n",
    "    info_type: str\n",
    "    method: str\n",
    "    toolflow: str\n",
    "\n",
    "@dataclass\n",
    "class ToolDB:\n",
    "    id: int\n",
    "    name: str\n",
    "    info_items: str\n",
    "    organization_system: str\n",
    "    phase_quality: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database in the `main.py`. We should also enable foreign key constraints. These are disabled by default in Sqlite.\n",
    "\n",
    "For testing purposes in this module we will use `db = database(\":memory:\")` to create an in-memory database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_db(loc=\"static/infoflow.db\"):\n",
    "    db = database(loc)\n",
    "    db.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "    inf_tbl = db.create(InformationItemDB)\n",
    "    tool_tbl = db.create(ToolDB)\n",
    "    impr_tbl = db.create(ImprovementDB)\n",
    "    return inf_tbl, tool_tbl, impr_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "We can add foreign key constraints to the tables using the `transform` method from `sqlite_utils`.\n",
    "\n",
    "```python\n",
    "inf_tbl.transform(add_foreign_keys=[(\"<field_name>\", \"<table_name_to_connect>\", \"<field_name_in_table_to_connect>\")])\n",
    "```\n",
    ":::\n",
    "\n",
    "But for now we won't use foreign key constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests and usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_tbl, tool_tbl, imp_tbl = create_db(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(cid=0, name='id', type='INTEGER', notnull=0, default_value=None, is_pk=1),\n",
       " Column(cid=1, name='info_type', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=2, name='method', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=3, name='toolflow', type='TEXT', notnull=0, default_value=None, is_pk=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_tbl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instances for information items, tools and improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_item = InformationItem(\n",
    "    info_type=InformationType.BOOK,\n",
    "    method=[Method.MANUAL, Method.AUTOMATIC], \n",
    "    toolflow=[\"collect\", \"process\"]\n",
    ")\n",
    "\n",
    "obsidian = Tool(\n",
    "    name=\"Obsidian\",\n",
    "    info_items=[info_item],\n",
    "    organization_system=[OrganizationSystem.TAGS, OrganizationSystem.LINKS],\n",
    "    phase_quality=[PhaseQuality.GREAT, PhaseQuality.OK]\n",
    ")\n",
    "\n",
    "improvement_item = Improvement(\n",
    "    title=\"Better search functionality\",\n",
    "    what=\"Better search functionality\",\n",
    "    why=\"Current search is too slow\",\n",
    "    prio=1,\n",
    "    tool=obsidian,\n",
    "    phase=Phase.RETRIEVE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the instances to the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSerializationError",
     "evalue": "Error calling function `db_serialize`: TypeError: Object of type InformationItem is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mTool.db_serialize\u001b[39m\u001b[34m(self, v)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(v.value) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03ma serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m(to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type InformationItem is not JSON serializable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPydanticSerializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mobsidian\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/infoflow/.venv/lib/python3.11/site-packages/pydantic/main.py:463\u001b[39m, in \u001b[36mBaseModel.model_dump\u001b[39m\u001b[34m(self, mode, include, exclude, context, by_alias, exclude_unset, exclude_defaults, exclude_none, round_trip, warnings, fallback, serialize_as_any)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    423\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    435\u001b[39m     serialize_as_any: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    436\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"!!! abstract \"Usage Documentation\"\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m        [`model_dump`](../concepts/serialization.md#modelmodel_dump)\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m \u001b[33;03m        A dictionary representation of the model.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_serializer__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPydanticSerializationError\u001b[39m: Error calling function `db_serialize`: TypeError: Object of type InformationItem is not JSON serializable"
     ]
    }
   ],
   "source": [
    "obsidian.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSerializationError",
     "evalue": "Error calling function `db_serialize`: TypeError: Object of type InformationItem is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mTool.db_serialize\u001b[39m\u001b[34m(self, v)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(v.value) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03ma serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m(to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type InformationItem is not JSON serializable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPydanticSerializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inf_tbl.insert(info_item.model_dump())\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tool_tbl.insert(\u001b[43mobsidian\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      3\u001b[39m imp_tbl.insert(improvement_item.model_dump())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/infoflow/.venv/lib/python3.11/site-packages/pydantic/main.py:463\u001b[39m, in \u001b[36mBaseModel.model_dump\u001b[39m\u001b[34m(self, mode, include, exclude, context, by_alias, exclude_unset, exclude_defaults, exclude_none, round_trip, warnings, fallback, serialize_as_any)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    423\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    435\u001b[39m     serialize_as_any: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    436\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"!!! abstract \"Usage Documentation\"\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m        [`model_dump`](../concepts/serialization.md#modelmodel_dump)\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m \u001b[33;03m        A dictionary representation of the model.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_serializer__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPydanticSerializationError\u001b[39m: Error calling function `db_serialize`: TypeError: Object of type InformationItem is not JSON serializable"
     ]
    }
   ],
   "source": [
    "inf_tbl.insert(info_item.model_dump())\n",
    "tool_tbl.insert(obsidian.model_dump())\n",
    "imp_tbl.insert(improvement_item.model_dump())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

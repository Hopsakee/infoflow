{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and create the SQLite database\n",
    "\n",
    "> This module defines the classes we use to represent the PKM workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp classdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import List, Union, ClassVar\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, field_serializer, field_validator, Field\n",
    "from fastlite import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `from __future__ import annotations` to support forward references in type hints. To be precise in the `@classmethod` we create to keep track of all instances of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the possible values of the different variables that are available in the classes. We use the module `enum` to define **Enumerations**. We use this to bind the possible values to a variable name, making the code more readable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationType(Enum):\n",
    "    \"\"\"Information content types that flow through the PKM workflow.\"\"\"\n",
    "    BOOK = \"book\"\n",
    "    RESEARCH_PAPER = \"research_paper\"\n",
    "    DOCUMENT = \"document\"\n",
    "    ANNOTATION = \"annotations&highlights\"\n",
    "    NOTE = \"note\"\n",
    "    EMAIL = \"email\"\n",
    "    DISCORD_MESSAGE = \"discord_message\"\n",
    "    WEB_ARTICLE = \"web_article\"\n",
    "    YOUTUBE_VIDEO = \"youtube_video\"\n",
    "    PODCAST = \"podcast\"\n",
    "    PRODUCT_IDEA = \"product_idea\"\n",
    "    PROJECT_IDEA = \"project_idea\"\n",
    "\n",
    "class Method(Enum):\n",
    "    \"\"\"How actions are performed - manually or automatically.\"\"\"\n",
    "    MANUAL = \"manual\"\n",
    "    AUTOMATIC = \"automatic\"\n",
    "\n",
    "class Phase(Enum):\n",
    "    \"\"\"The five phases of the PKM workflow.\"\"\"\n",
    "    COLLECT = \"collect\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    CONSUME = \"consume\"\n",
    "    EXTRACT = \"extract\"\n",
    "    REFINE = \"refine\"\n",
    "\n",
    "class PhaseQuality(Enum):\n",
    "    \"\"\"Quality rating for how well a tool performs in each phase.\"\"\"\n",
    "    NA = \"na\"\n",
    "    BAD = \"bad\"\n",
    "    OK = \"ok\"\n",
    "    GREAT = \"great\"\n",
    "\n",
    "class OrganizationSystem(Enum):\n",
    "    \"\"\"How tools organize and structure information.\"\"\"\n",
    "    TAGS = \"tags\"\n",
    "    FOLDERS = \"folders\"\n",
    "    LINKS = \"links\"\n",
    "    JOHNNY_DECIMAL = \"johnny_decimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Phase.REFINE: 'refine'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phase(\"refine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKM Workflow Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a dataclass for each item we need to be present in the PKM workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track instances of classes\n",
    "\n",
    "We also want to keep track of the instances available for each class. Therefore we need some higher order magic.\n",
    "\n",
    "- a list in the class to store the instances\n",
    "- a __init__ method to add the instance to the list\n",
    "- a classmethod to get the list of instances\n",
    "\n",
    "We can't just add a `_instances = []` statement to the Class, because Pydantic will then assume it is a model field (private attribute). We need to tell Pydantic to ignore the _instances class variable as a model field and treat is as a class variable. Therefore we need to import `ClassVar` from `typing` and use it to type the _instances variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pydantic with MiniDataAPI and SQLite\n",
    "\n",
    "We want to use `Pydantic` Dataclasses to enable typechecking and validation. We also want to use the Dataclasses with the `MiniDataAPI` to create the tables in the `SQLite` database. But `SQLite` only has datatypes: `NULL`, `INTEGER`, `REAL`, `TEXT`, and `BLOB`. So no `list` or any of the Dataclass(Enum) types we use.\n",
    "\n",
    "To be able to use both `Pydanctic` and the `MiniDataAPI` we will do two things:\n",
    "\n",
    "1. Define a Pydantic Dataclass with the correct datatypes and a Dataclass that has the same fields as the Pydantic Dataclass, but with datatypes that can be used with SQLite.\n",
    "2. We add `@field_serializer` and `@field_validator` methods to the Pydantic Dataclass that convert the fields to JSON strings when we use the method `.model_dump()` on the instance of the Pydantic Dataclass.\n",
    "\n",
    "This way we can:\n",
    "\n",
    "- create the SQLite database tables using the regular Dataclasses.\n",
    "- create instances with the Pydantic Dataclass to have easy typechecking and validation.\n",
    "- convert this instances to `MiniDataAPI` and `SQLite` friendly datatypes using `.model_dump()` on the instance.\n",
    "\n",
    "```python\n",
    "class InformationItem(BaseModel):\n",
    "    info_type: InformationType\n",
    "    method: list[Union[Method, None]]\n",
    "    toolflow: list[str]\n",
    "    \n",
    "    # Convert Enum to string and list to JSON string so we can add to SQLite\n",
    "    @field_serializer('info_type', 'method', 'toolflow')\n",
    "    def serialize_lists(self, v):\n",
    "        if isintance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else str(v)\n",
    "    \n",
    "    # Convert JSON string from SQLite to list of Enum and strings\n",
    "    @field_validator('method', 'toolflow', mode='before')\n",
    "    def parse_json_lists(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return json.loads(v)\n",
    "        return v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pydantic Dataclasses**\n",
    "\n",
    "Used for typechecking.\n",
    "\n",
    "When creating a new instance for an `InformationItem` the `toolflow` must be given as a list of `Tool` objects. The typechecking makes sure that any `Tool` object mentioned in the `toolfow` list, does exist as an actual `Tool` instance. So make sure to first create  all the `Tool` instances that are needed for an `InformationItem`, before creating the `InformationItem` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "I had some serious trouble getting the Pydantic dataclass validations to work. One of the issues is described above and is about SQLite not supporting all datatypes. A second major issue is that the Pydantic Dataclasses reference each other. The `InformationItem` references the `Tool` in the `toolflow` field. I would also be convenient to store all the `InformationItem`s that can be used with a certain `Tool`, but in that case we would create a circular reference between `InformationItem` and `Tool`.\n",
    "\n",
    "We decided to remove the `information_items` list from `Tool`. When we need to get all the `InformationItem`s that are supported by a `Tool` we can write a Python function or do a SQL-query on the SQLite database.\n",
    "\n",
    "But then we are left with the fact that we want a list of `Tool`s that exist. These are the options considered:\n",
    "\n",
    "- `toolflow: list[Tool]`\n",
    "- `toolflow: list[Tool.name]`\n",
    "- `toolflow: list[str]`\n",
    "\n",
    "The last option is used in combination with validation to ensure each string is a valid Tool.name.\n",
    "\n",
    "Here's why this is the best approach:\n",
    "\n",
    "- Clean serialization (no complex object embedding)\n",
    "- Human-readable in the database\n",
    "- Type safety through validation\n",
    "- Easy to query\n",
    "\n",
    "The same goes for the `Improvement` class and the field `tool`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationItem(BaseModel):\n",
    "    \"\"\"Represents an information item flowing through the PKM workflow.\"\"\"\n",
    "    name: str = Field(..., description=\"Name of the information item\")\n",
    "    info_type: InformationType = Field(..., description=\"Type of information item, e.g. book, article, video, etc.\")\n",
    "    method: list[Union[Method, None]] = Field(..., description=\"Methods used at each phase in order: collect, retrieve, consume, extract, refine\")\n",
    "    toolflow: list[Union[str, list[str], tuple[str], None]] = Field(..., description=\"Tools used for this item at each phase in order: collect, retrieve, consume, extract, refine\")\n",
    "\n",
    "    _instances: ClassVar[List[InformationItem]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> list[InformationItem]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('info_type','method', 'toolflow')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('info_type','method', 'toolflow', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value\n",
    "    \n",
    "    @field_validator('toolflow')\n",
    "    def validate_tool_names(cls, v):\n",
    "        if len(v) != 5:\n",
    "            raise ValueError(f\"Toolflow must have 5 tools, got {len(v)}\")\n",
    "        valid_tools = {tool.name for tool in Tool.get_instances()}\n",
    "        for p in v: # Phase-tools\n",
    "            if p is None:\n",
    "                continue\n",
    "            elif isinstance(p, str): # Case of single tool in phase\n",
    "                if p not in valid_tools: raise ValueError(f\"Tool '{p}' does not exist\")\n",
    "            elif isinstance(p, (list, tuple)): # Case of multiple tools in phase\n",
    "                for t in p:\n",
    "                    if t not in valid_tools: raise ValueError(f\"Tool '{t}' does not exist\")\n",
    "            else:\n",
    "                raise ValueError(f\"Tool '{p}' is not a string or list of strings or tuple of strings\")\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    \"\"\"Represents a PKM tool with information on the supported OrganizationSystems and for each Phase the perceived quality.\"\"\"\n",
    "    name: str = Field(..., description=\"Name of the tool\")\n",
    "    organization_system: list[OrganizationSystem] = Field(..., description=\"Organization systems supported by the tool\")\n",
    "    phase_quality: list[PhaseQuality] = Field(..., description=\"Quality of the tool for each phase in order: collect, retrieve, consume, extract, refine\")\n",
    "\n",
    "    _instances: ClassVar[List[Tool]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> list[Tool]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('organization_system', 'phase_quality')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('organization_system', 'phase_quality', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value\n",
    "    \n",
    "    @field_validator('phase_quality')\n",
    "    def validate_phase_quality(cls, v):\n",
    "        if len(v) != 5:\n",
    "            raise ValueError(f\"Phase quality must have 5 phases, got {len(v)}\")\n",
    "        return v\n",
    "    \n",
    "\n",
    "class Improvement(BaseModel):\n",
    "    \"\"\"Tracks workflow improvements needed for better PKM effectiveness.\"\"\"\n",
    "    title: str = Field(..., description=\"Title of the improvement\")\n",
    "    what: str = Field(..., description=\"What needs to be improved\")\n",
    "    why: str = Field(..., description=\"Why is this improvement needed\")\n",
    "    prio: int = Field(..., description=\"Priority of the improvement\")\n",
    "    tool: str = Field(..., description=\"Tool that needs improvement\")\n",
    "    phase: Phase = Field(..., description=\"Phase that needs improvement\")\n",
    "\n",
    "    _instances: ClassVar[List[Improvement]] = []\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances.append(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> list[Improvement]:\n",
    "        return cls._instances.copy()\n",
    "    \n",
    "    @field_serializer('tool', 'phase')\n",
    "    def db_serialize(self, v):\n",
    "        if isinstance(v, list):\n",
    "            return json.dumps([i.value if hasattr(i, 'value') else i for i in v])\n",
    "        return str(v.value) if hasattr(v, 'value') else v\n",
    "    \n",
    "    @field_validator('phase', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value)\n",
    "        return value\n",
    "    \n",
    "    @field_validator('tool')\n",
    "    def validate_tool_names(cls, v):\n",
    "        valid_tools = {tool.name for tool in Tool.get_instances()}\n",
    "        if v not in valid_tools:\n",
    "            raise ValueError(f\"Tool '{tool_name}' does not exist\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test creating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Tool(name=\"reader\", organization_system=[OrganizationSystem.TAGS], phase_quality=[PhaseQuality.GREAT, PhaseQuality.OK, PhaseQuality.OK, PhaseQuality.OK, PhaseQuality.OK])\n",
    "obsidian = Tool(name=\"obsidian\", organization_system=[OrganizationSystem.TAGS], phase_quality=[PhaseQuality.GREAT, PhaseQuality.BAD, PhaseQuality.BAD, PhaseQuality.BAD, PhaseQuality.BAD])\n",
    "inf_a = InformationItem(name=\"infoitem_a\", info_type=InformationType.BOOK, method=[Method.MANUAL], toolflow=[(\"reader\", \"obsidian\"), \"obsidian\", \"reader\", \"obsidian\", \"reader\"])\n",
    "imp_a = Improvement(title=\"improvement_a\", what=\"gras\", why=\"dus\", prio=0, tool=\"reader\", phase=Phase.COLLECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test creating list of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(Improvement.get_instances()), 1)\n",
    "test_eq(len(Tool.get_instances()), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular Dataclasses with SQLite datatypes**\n",
    "\n",
    "Used for creating the tables in the SQLite database.\n",
    "These contain the same fields as the Pydantic Dataclasses we defined above. But these Dataclasses only contain datatypes that are supported by SQLite and have an `id: int` field added as a primary key and use the build-in `@dataclass` decorator, because `FastLite` doesn't support Pydantic Dataclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ImprovementDB:\n",
    "    id: int\n",
    "    title: str\n",
    "    what: str\n",
    "    why: str\n",
    "    prio: int\n",
    "    tool: str\n",
    "    phase: str\n",
    "\n",
    "@dataclass\n",
    "class InformationItemDB:\n",
    "    id: int\n",
    "    name: str\n",
    "    info_type: str\n",
    "    method: str\n",
    "    toolflow: str\n",
    "\n",
    "@dataclass\n",
    "class ToolDB:\n",
    "    id: int\n",
    "    name: str\n",
    "    organization_system: str\n",
    "    phase_quality: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tre = [(\"koe\", \"honderd\"), None, \"hond\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hond\" in tre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"koe\" in tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database in the `main.py`. We should also enable foreign key constraints. These are disabled by default in Sqlite.\n",
    "\n",
    "For testing purposes in this module we will use `db = database(\":memory:\")` to create an in-memory database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_db(loc=\"static/infoflow.db\"):\n",
    "    db = database(loc)\n",
    "    db.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "    inf_tbl = db.create(InformationItemDB)\n",
    "    tool_tbl = db.create(ToolDB)\n",
    "    impr_tbl = db.create(ImprovementDB)\n",
    "    return db, inf_tbl, tool_tbl, impr_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "We can add foreign key constraints to the tables using the `transform` method from `sqlite_utils`.\n",
    "\n",
    "```python\n",
    "inf_tbl.transform(add_foreign_keys=[(\"<field_name>\", \"<table_name_to_connect>\", \"<field_name_in_table_to_connect>\")])\n",
    "```\n",
    ":::\n",
    "\n",
    "But for now we won't use foreign key constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests and usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, inf_tbl, tool_tbl, imp_tbl = create_db(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(cid=0, name='id', type='INTEGER', notnull=0, default_value=None, is_pk=1),\n",
       " Column(cid=1, name='name', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=2, name='info_type', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=3, name='method', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=4, name='toolflow', type='TEXT', notnull=0, default_value=None, is_pk=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_tbl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the previously created instances to the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'reader',\n",
       " 'organization_system': '[\"tags\"]',\n",
       " 'phase_quality': '[\"great\", \"ok\"]'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'infoitem_a',\n",
       " 'info_type': 'book',\n",
       " 'method': '[\"manual\"]',\n",
       " 'toolflow': '[\"reader\", \"obsidian\"]'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_a.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'improvement_a',\n",
       " 'what': 'gras',\n",
       " 'why': 'dus',\n",
       " 'prio': 0,\n",
       " 'tool': 'reader',\n",
       " 'phase': 'collect'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_a.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImprovementDB(id=1, title='improvement_a', what='gras', why='dus', prio=0, tool='reader', phase='collect')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl.insert(reader.model_dump())\n",
    "tool_tbl.insert(obsidian.model_dump())\n",
    "inf_tbl.insert(inf_a.model_dump())\n",
    "imp_tbl.insert(imp_a.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now retrieve the info from the database as intances from the Pydantic Dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "improvement_db, information_item_db, tool_db"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'name': 'reader',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"ok\"]'},\n",
       " {'id': 2,\n",
       "  'name': 'obsidian',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"bad\"]'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.t.tool_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='reader', organization_system=[<OrganizationSystem.TAGS: 'tags'>], phase_quality=[<PhaseQuality.GREAT: 'great'>, <PhaseQuality.OK: 'ok'>])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_back_from_sqlite_1 = Tool(**db.t.tool_db()[0])\n",
    "reader_back_from_sqlite_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolDB(id=1, name='reader', organization_system='[\"tags\"]', phase_quality='[\"great\", \"ok\"]'),\n",
       " ToolDB(id=2, name='obsidian', organization_system='[\"tags\"]', phase_quality='[\"great\", \"bad\"]')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolDB(id=1, name='reader', organization_system='[\"tags\"]', phase_quality='[\"great\", \"ok\"]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='reader', organization_system=[<OrganizationSystem.TAGS: 'tags'>], phase_quality=[<PhaseQuality.GREAT: 'great'>, <PhaseQuality.OK: 'ok'>])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_back_from_sqlite_2 = Tool(**tool_tbl()[0].__dict__)\n",
    "reader_back_from_sqlite_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

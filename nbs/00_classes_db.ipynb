{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and create the SQLite database\n",
    "\n",
    "> This module defines the classes we use to represent the PKM workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp classdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import Union, ClassVar\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, field_serializer, field_validator, Field, computed_field\n",
    "from fastlite import *\n",
    "from fastcore.test import *\n",
    "from hopsa import ossys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `from __future__ import annotations` to support forward references in type hints. To be precise in the `@classmethod` we create to keep track of all instances of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pydantic with MiniDataAPI and SQLite\n",
    "\n",
    "We want to use `Pydantic` Dataclasses to enable typechecking and validation. We also want to use the Dataclasses with the `MiniDataAPI` to create the tables in the `SQLite` database. But `SQLite` only has datatypes: `NULL`, `INTEGER`, `REAL`, `TEXT`, and `BLOB`. So no `list` or any of the Dataclass(Enum) types we use.\n",
    "\n",
    "To be able to use both `Pydanctic` and the `MiniDataAPI` we will do two things:\n",
    "\n",
    "1. Define a Pydantic Dataclass with the correct datatypes and a Dataclass that has the same fields as the Pydantic Dataclass, but with datatypes that can be used with SQLite.\n",
    "2. We add `@field_serializer` methods to the Pydantic Dataclass that convert the fields to JSON strings when we use the method `.model_dump()` on the instance of the Pydantic Dataclass. These serialised JSON strings can then be added to the SQLite database.\n",
    "3. We also use the `@field_validator` decorator to convert the JSON strings back to the correct datatypes when we load the data from the SQLite database back into the Pydantic Dataclass.\n",
    "\n",
    "This way we can:\n",
    "\n",
    "- create instances with the Pydantic Dataclass to have easy typechecking and validation.\n",
    "- convert this instances to `MiniDataAPI` and `SQLite` friendly datatypes using `.model_dump()` on the instance, that we can then add to the database.\n",
    "- load the data from the SQLite database back into the Pydantic Dataclass.\n",
    "\n",
    "The exact implementation can be found below where the Classes are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track instances of classes\n",
    "\n",
    "We also want to keep track of the instances available for each class. Therefore we need some higher order magic.\n",
    "\n",
    "- a list in the class to store the instances\n",
    "- a __init__ method to add the instance to the list\n",
    "- a classmethod to get the list of instances\n",
    "\n",
    "We can't just add a `_instances = []` statement to the Class, because Pydantic will then assume it is a model field (private attribute). We need to tell Pydantic to ignore the _instances class variable as a model field and treat is as a class variable. Therefore we need to import `ClassVar` from `typing` and use it to type the _instances variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the possible values of the different variables that are available in the classes. We use the module `enum` to define **Enumerations**. We use this to bind the possible values to a variable name, making the code more readable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationType(Enum):\n",
    "    \"\"\"Information content types that flow through the PKM workflow.\"\"\"\n",
    "    BOOK = \"book\"\n",
    "    RESEARCH_PAPER = \"research_paper\"\n",
    "    DOCUMENT = \"document\"\n",
    "    ANNOTATION = \"annotations&highlights\"\n",
    "    NOTE = \"note\"\n",
    "    EMAIL = \"email\"\n",
    "    DISCORD_MESSAGE = \"discord_message\"\n",
    "    WEB_ARTICLE = \"web_article\"\n",
    "    YOUTUBE_VIDEO = \"youtube_video\"\n",
    "    PODCAST = \"podcast\"\n",
    "    PRODUCT_IDEA = \"product_idea\"\n",
    "    PROJECT_IDEA = \"project_idea\"\n",
    "\n",
    "class Method(Enum):\n",
    "    \"\"\"How actions are performed - manually or automatically.\"\"\"\n",
    "    MANUAL = \"manual\"\n",
    "    AUTOMATIC = \"automatic\"\n",
    "\n",
    "class Phase(Enum):\n",
    "    \"\"\"The five phases of the PKM workflow.\"\"\"\n",
    "    COLLECT = \"collect\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    CONSUME = \"consume\"\n",
    "    EXTRACT = \"extract\"\n",
    "    REFINE = \"refine\"\n",
    "\n",
    "class PhaseQuality(Enum):\n",
    "    \"\"\"Quality rating for how well a tool performs in each phase.\"\"\"\n",
    "    NA = \"na\"\n",
    "    BAD = \"bad\"\n",
    "    OK = \"ok\"\n",
    "    GREAT = \"great\"\n",
    "\n",
    "class OrganizationSystem(Enum):\n",
    "    \"\"\"How tools organize and structure information.\"\"\"\n",
    "    TAGS = \"tags\"\n",
    "    FOLDERS = \"folders\"\n",
    "    LINKS = \"links\"\n",
    "    JOHNNY_DECIMAL = \"johnny_decimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Phase.REFINE: 'refine'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phase(\"refine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKM Workflow Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a dataclass for each item we need to be present in the PKM workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pydantic Dataclasses**\n",
    "\n",
    "Used for typechecking.\n",
    "\n",
    "When creating a new instance for an `InformationItem` the `toolflow` must be given as a list of `Tool` objects. The typechecking makes sure that any `Tool` object mentioned in the `toolfow` list, does exist as an actual `Tool` instance. So make sure to first create  all the `Tool` instances that are needed for an `InformationItem`, before creating the `InformationItem` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "I had some serious trouble getting the Pydantic dataclass validations to work. One of the issues is described above and is about SQLite not supporting all datatypes. A second major issue is that the Pydantic Dataclasses reference each other. The `InformationItem` references the `Tool` in the `toolflow` field. I would also be convenient to store all the `InformationItem`s that can be used with a certain `Tool`, but in that case we would create a circular reference between `InformationItem` and `Tool`.\n",
    "\n",
    "We decided to remove the `information_items` list from `Tool`. When we need to get all the `InformationItem`s that are supported by a `Tool` we can write a Python function or do a SQL-query on the SQLite database.\n",
    "\n",
    "But then we are left with the fact that we want a list of `Tool`s that exist. These are the options considered:\n",
    "\n",
    "- `toolflow: list[Tool]`\n",
    "- `toolflow: list[Tool.name]`\n",
    "- `toolflow: list[str]`\n",
    "\n",
    "The last option is used in combination with validation to ensure each string is a valid Tool.name.\n",
    "\n",
    "Here's why this is the best approach:\n",
    "\n",
    "- Clean serialization (no complex object embedding)\n",
    "- Human-readable in the database\n",
    "- Type safety through validation\n",
    "- Easy to query\n",
    "\n",
    "The same goes for the `Improvement` class and the field `tool`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PhaseQualityData(BaseModel):\n",
    "    collect: PhaseQuality\n",
    "    retrieve: PhaseQuality\n",
    "    consume: PhaseQuality\n",
    "    extract: PhaseQuality\n",
    "    refine: PhaseQuality\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the tool\")\n",
    "    organization_system: list[OrganizationSystem] = Field(..., description=\"Organization systems supported by the tool\")\n",
    "    phase_quality: PhaseQualityData = Field(..., description=\"Quality of the tool for each phase\")\n",
    "    collect: str | None = Field(default=None, description=\"Description how to use tool in collect phase\")\n",
    "    retrieve: str | None = Field(default=None, description=\"Description how to use tool in retrieve phase\")\n",
    "    consume: str | None = Field(default=None, description=\"Description how to use tool in consume phase\")\n",
    "    extract: str | None = Field(default=None, description=\"Description how to use tool in extract phase\")\n",
    "    refine: str | None = Field(default=None, description=\"Description how to use tool in refine phase\")\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def slug(self) -> str:\n",
    "        return ossys.sanitize_name(self.name)\n",
    "\n",
    "    def flatten_for_db(self):\n",
    "        base = self.model_dump(exclude={'phase_quality'})\n",
    "        base.update({'collect_quality': self.phase_quality.collect.value, 'retrieve_quality': self.phase_quality.retrieve.value, 'consume_quality': self.phase_quality.consume.value, 'extract_quality': self.phase_quality.extract.value, 'refine_quality': self.phase_quality.refine.value})\n",
    "        return base\n",
    "\n",
    "    _instances: ClassVar[Dict[str, Tool]] = {}\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances[self.slug] = self\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> Dict[str, Tool]:\n",
    "        return cls._instances\n",
    "    \n",
    "    @field_serializer('organization_system')\n",
    "    def db_serialize(self, v):\n",
    "        return json.dumps([i.value for i in v])\n",
    "    \n",
    "    @field_validator('organization_system', mode='before')\n",
    "    def parse_json_lists(cls, value):\n",
    "        if isinstance(value, str): return json.loads(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PhaseMethodData(BaseModel):\n",
    "    collect: Method | None\n",
    "    retrieve: Method | None\n",
    "    consume: Method | None\n",
    "    extract: Method | None\n",
    "    refine: Method | None\n",
    "\n",
    "class PhaseToolflowData(BaseModel):\n",
    "    collect: Union[str, list[str], tuple[str], None]\n",
    "    retrieve: Union[str, list[str], tuple[str], None]\n",
    "    consume: Union[str, list[str], tuple[str], None]\n",
    "    extract: Union[str, list[str], tuple[str], None]\n",
    "    refine: Union[str, list[str], tuple[str], None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InformationItem(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the information item\")\n",
    "    info_type: InformationType = Field(..., description=\"Type of information item, e.g. book, article, video, etc.\")\n",
    "    method: PhaseMethodData = Field(..., description=\"Methods used at each phase\")\n",
    "    toolflow: PhaseToolflowData = Field(..., description=\"Tools used for this item at each phase\")\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def slug(self) -> str:\n",
    "        return ossys.sanitize_name(self.name)\n",
    "\n",
    "    def flatten_for_db(self):\n",
    "        base = self.model_dump(exclude={'method', 'toolflow'})\n",
    "        base.update({'collect_method': self.method.collect.value if self.method.collect else None, 'retrieve_method': self.method.retrieve.value if self.method.retrieve else None, 'consume_method': self.method.consume.value if self.method.consume else None, 'extract_method': self.method.extract.value if self.method.extract else None, 'refine_method': self.method.refine.value if self.method.refine else None, 'collect_toolflow': json.dumps(self.toolflow.collect) if isinstance(self.toolflow.collect, (list, tuple)) else self.toolflow.collect, 'retrieve_toolflow': json.dumps(self.toolflow.retrieve) if isinstance(self.toolflow.retrieve, (list, tuple)) else self.toolflow.retrieve, 'consume_toolflow': json.dumps(self.toolflow.consume) if isinstance(self.toolflow.consume, (list, tuple)) else self.toolflow.consume, 'extract_toolflow': json.dumps(self.toolflow.extract) if isinstance(self.toolflow.extract, (list, tuple)) else self.toolflow.extract, 'refine_toolflow': json.dumps(self.toolflow.refine) if isinstance(self.toolflow.refine, (list, tuple)) else self.toolflow.refine})\n",
    "        return base\n",
    "\n",
    "    _instances: ClassVar[Dict[str, InformationItem]] = {}\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances[self.slug] = self\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> Dict[str, InformationItem]:\n",
    "        return cls._instances\n",
    "    \n",
    "    @field_serializer('info_type')\n",
    "    def db_serialize(self, v):\n",
    "        return v.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Improvement(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the improvement\")\n",
    "    what: str = Field(..., description=\"What needs to be improved\")\n",
    "    why: str = Field(..., description=\"Why is this improvement needed\")\n",
    "    prio: int = Field(..., description=\"Priority of the improvement\")\n",
    "    tool: str = Field(..., description=\"Tool that needs improvement\")\n",
    "    phase: Phase = Field(..., description=\"Phase that needs improvement\")\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def slug(self) -> str:\n",
    "        return ossys.sanitize_name(self.title)\n",
    "\n",
    "    def flatten_for_db(self):\n",
    "        return self.model_dump()\n",
    "\n",
    "    _instances: ClassVar[Dict[str, Improvement]] = {}\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        type(self)._instances[self.slug] = self\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instances(cls) -> Dict[str, Improvement]:\n",
    "        return cls._instances\n",
    "    \n",
    "    @field_serializer('phase')\n",
    "    def db_serialize(self, v):\n",
    "        return v.value\n",
    "    \n",
    "    @field_validator('tool')\n",
    "    def validate_tool_names(cls, v):\n",
    "        valid_tools = Tool.get_instances().keys()\n",
    "        if v not in valid_tools: raise ValueError(f\"Tool '{v}' does not exist\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test creating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_phase_quality_data():\n",
    "    pqd = PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT)\n",
    "    test_eq(pqd.collect, PhaseQuality.GREAT)\n",
    "    test_eq(pqd.retrieve, PhaseQuality.BAD)\n",
    "\n",
    "def test_tool_creation():\n",
    "    tool = Tool(name=\"TestTool\", organization_system=[OrganizationSystem.TAGS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n",
    "    test_eq(tool.name, \"TestTool\")\n",
    "    test_eq(tool.slug, \"testtool\")\n",
    "    test_eq(tool.phase_quality.collect, PhaseQuality.GREAT)\n",
    "\n",
    "def test_tool_flatten():\n",
    "    tool = Tool(name=\"TestTool\", organization_system=[OrganizationSystem.TAGS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n",
    "    flat = tool.flatten_for_db()\n",
    "    test_eq(flat['collect_quality'], 'great')\n",
    "    test_eq(flat['retrieve_quality'], 'bad')\n",
    "    test_eq(flat['name'], 'TestTool')\n",
    "\n",
    "def test_information_item():\n",
    "    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n",
    "    tools = PhaseToolflowData(collect=\"Reader\", retrieve=\"Recall\", consume=None, extract=None, refine=None)\n",
    "    item = InformationItem(name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n",
    "    test_eq(item.method.collect, Method.MANUAL)\n",
    "    test_eq(item.toolflow.collect, \"Reader\")\n",
    "\n",
    "def test_information_item_flatten():\n",
    "    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n",
    "    tools = PhaseToolflowData(collect=[\"Reader\", \"Recall\"], retrieve=\"Recall\", consume=None, extract=None, refine=None)\n",
    "    item = InformationItem(name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n",
    "    flat = item.flatten_for_db()\n",
    "    test_eq(flat['collect_method'], 'manual')\n",
    "    test_eq(flat['retrieve_method'], None)\n",
    "    test_eq(flat['collect_toolflow'], '[\"Reader\", \"Recall\"]')\n",
    "    test_eq(flat['retrieve_toolflow'], 'Recall')\n",
    "\n",
    "def test_improvement():\n",
    "    imp = Improvement(title=\"Fix Search\", what=\"Better search in Reader\", why=\"Current search is bad\", prio=1, tool=\"testtool\", phase=Phase.RETRIEVE)\n",
    "    test_eq(imp.title, \"Fix Search\")\n",
    "    test_eq(imp.phase, Phase.RETRIEVE)\n",
    "    test_eq(imp.flatten_for_db()['phase'], 'retrieve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phase_quality_data()\n",
    "test_tool_creation()\n",
    "test_tool_flatten()\n",
    "test_information_item()\n",
    "test_information_item_flatten()\n",
    "test_improvement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testtool': Tool(name='TestTool', organization_system=[<OrganizationSystem.TAGS: 'tags'>], phase_quality=PhaseQualityData(collect=<PhaseQuality.GREAT: 'great'>, retrieve=<PhaseQuality.BAD: 'bad'>, consume=<PhaseQuality.OK: 'ok'>, extract=<PhaseQuality.NA: 'na'>, refine=<PhaseQuality.GREAT: 'great'>), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='testtool')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tool.get_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_article': InformationItem(name='Test Article', info_type=<InformationType.WEB_ARTICLE: 'web_article'>, method=PhaseMethodData(collect=<Method.MANUAL: 'manual'>, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=['Reader', 'Recall'], retrieve='Recall', consume=None, extract=None, refine=None), slug='test_article')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InformationItem.get_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fix_search': Improvement(title='Fix Search', what='Better search in Reader', why='Current search is bad', prio=1, tool='testtool', phase=<Phase.RETRIEVE: 'retrieve'>, slug='fix_search')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Improvement.get_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database in the `main.py`. We should also enable foreign key constraints. These are disabled by default in Sqlite.\n",
    "\n",
    "For testing purposes in this module we will use `db = database(\":memory:\")` to create an in-memory database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_db(loc=\"static/infoflow.db\"):\n",
    "    db = database(loc)\n",
    "    db.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "    inf_tbl = db.create(InformationItemDB)\n",
    "    tool_tbl = db.create(ToolDB)\n",
    "    impr_tbl = db.create(ImprovementDB)\n",
    "    return db, inf_tbl, tool_tbl, impr_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "We can add foreign key constraints to the tables using the `transform` method from `sqlite_utils`.\n",
    "\n",
    "```python\n",
    "inf_tbl.transform(add_foreign_keys=[(\"<field_name>\", \"<table_name_to_connect>\", \"<field_name_in_table_to_connect>\")])\n",
    "```\n",
    ":::\n",
    "\n",
    "But for now we won't use foreign key constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests and usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, inf_tbl, tool_tbl, imp_tbl = create_db(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(cid=0, name='id', type='INTEGER', notnull=0, default_value=None, is_pk=1),\n",
       " Column(cid=1, name='slug', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=2, name='name', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=3, name='info_type', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=4, name='method', type='TEXT', notnull=0, default_value=None, is_pk=0),\n",
       " Column(cid=5, name='toolflow', type='TEXT', notnull=0, default_value=None, is_pk=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_tbl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add data to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the previously created instances to the SQLite tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'improvement_a',\n",
       " 'what': 'gras',\n",
       " 'why': 'dus',\n",
       " 'prio': 0,\n",
       " 'tool': 'reader',\n",
       " 'phase': 'collect',\n",
       " 'slug': 'improvement_a'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Improvement.get_instances()['improvement_a'].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a single instance to the SQLite table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InformationItemDB(id=1, slug='infoitem_a', name='infoitem_a', info_type='book', method='[\"manual\"]', toolflow='[[\"reader\", \"obsidian\"], \"obsidian\", \"reader\", \"obsidian\", \"reader\"]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_tbl.insert(Improvement.get_instances()['improvement_a'].model_dump())\n",
    "inf_tbl.insert(InformationItem.get_instances()['infoitem_a'].model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add multiple instances to the SQLite table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table tool_db (id, slug, name, organization_system, phase_quality, collect, retrieve, consume, extract, refine)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl.insert_all([t.model_dump() for t in Tool.get_instances().values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'slug': 'reader',\n",
       "  'name': 'reader',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"ok\", \"ok\", \"ok\", \"ok\"]',\n",
       "  'collect': None,\n",
       "  'retrieve': None,\n",
       "  'consume': None,\n",
       "  'extract': None,\n",
       "  'refine': None},\n",
       " {'id': 2,\n",
       "  'slug': 'obsidian',\n",
       "  'name': 'obsidian',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"bad\", \"bad\", \"bad\", \"bad\"]',\n",
       "  'collect': None,\n",
       "  'retrieve': None,\n",
       "  'consume': None,\n",
       "  'extract': None,\n",
       "  'refine': None}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in tool_tbl.rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now retrieve the info from the database as intances from the Pydantic Dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "improvement_db, information_item_db, tool_db"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastlite.core._TablesGetter"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(db.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'slug': 'reader',\n",
       "  'name': 'reader',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"ok\", \"ok\", \"ok\", \"ok\"]',\n",
       "  'collect': None,\n",
       "  'retrieve': None,\n",
       "  'consume': None,\n",
       "  'extract': None,\n",
       "  'refine': None},\n",
       " {'id': 2,\n",
       "  'slug': 'obsidian',\n",
       "  'name': 'obsidian',\n",
       "  'organization_system': '[\"tags\"]',\n",
       "  'phase_quality': '[\"great\", \"bad\", \"bad\", \"bad\", \"bad\"]',\n",
       "  'collect': None,\n",
       "  'retrieve': None,\n",
       "  'consume': None,\n",
       "  'extract': None,\n",
       "  'refine': None}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.t.tool_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='reader', organization_system=[<OrganizationSystem.TAGS: 'tags'>], phase_quality=[<PhaseQuality.GREAT: 'great'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>], collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_back_from_sqlite_1 = Tool(**db.t.tool_db()[0])\n",
    "reader_back_from_sqlite_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolDB(id=1, slug='reader', name='reader', organization_system='[\"tags\"]', phase_quality='[\"great\", \"ok\", \"ok\", \"ok\", \"ok\"]', collect=None, retrieve=None, consume=None, extract=None, refine=None),\n",
       " ToolDB(id=2, slug='obsidian', name='obsidian', organization_system='[\"tags\"]', phase_quality='[\"great\", \"bad\", \"bad\", \"bad\", \"bad\"]', collect=None, retrieve=None, consume=None, extract=None, refine=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolDB(id=1, slug='reader', name='reader', organization_system='[\"tags\"]', phase_quality='[\"great\", \"ok\", \"ok\", \"ok\", \"ok\"]', collect=None, retrieve=None, consume=None, extract=None, refine=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_tbl()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='reader', organization_system=[<OrganizationSystem.TAGS: 'tags'>], phase_quality=[<PhaseQuality.GREAT: 'great'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>, <PhaseQuality.OK: 'ok'>], collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_back_from_sqlite_2 = Tool(**tool_tbl()[0].__dict__)\n",
    "reader_back_from_sqlite_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def instns_to_db(db_tbl, cls_instns):\n",
    "    \"\"\"Add all instances from a given Class to the given database table\"\"\"\n",
    "    db_tbl.insert_all([t.model_dump() for t in cls_instns.get_instances().values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

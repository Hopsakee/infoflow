[
  {
    "objectID": "classes_db.html",
    "href": "classes_db.html",
    "title": "Define Classes and create the SQLite database",
    "section": "",
    "text": "We use from __future__ import annotations to support forward references in type hints. To be precise in the @classmethod we create to keep track of all instances of the class.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#using-pydantic-with-minidataapi-and-sqlite",
    "href": "classes_db.html#using-pydantic-with-minidataapi-and-sqlite",
    "title": "Define Classes and create the SQLite database",
    "section": "Using Pydantic with MiniDataAPI and SQLite",
    "text": "Using Pydantic with MiniDataAPI and SQLite\nWe want to use Pydantic Dataclasses to enable typechecking and validation. We also want to use the Dataclasses with the MiniDataAPI to create the tables in the SQLite database. But SQLite only has datatypes: NULL, INTEGER, REAL, TEXT, and BLOB. So no list or any of the Dataclass(Enum) types we use.\nTo be able to use both Pydanctic and the MiniDataAPI we will do two things:\n\nDefine a Pydantic Dataclass with the correct datatypes and a Dataclass that has the same fields as the Pydantic Dataclass, but with datatypes that can be used with SQLite.\nWe add @field_serializer methods to the Pydantic Dataclass that convert the fields to JSON strings when we use the method .model_dump() on the instance of the Pydantic Dataclass. These serialised JSON strings can then be added to the SQLite database.\nWe also use the @field_validator decorator to convert the JSON strings back to the correct datatypes when we load the data from the SQLite database back into the Pydantic Dataclass.\n\nThis way we can:\n\ncreate instances with the Pydantic Dataclass to have easy typechecking and validation.\nconvert this instances to MiniDataAPI and SQLite friendly datatypes using .model_dump() on the instance, that we can then add to the database.\nload the data from the SQLite database back into the Pydantic Dataclass.\n\nThe exact implementation can be found below where the Classes are defined.\n\nTrack instances of classes\nWe also want to keep track of the instances available for each class. Therefore we need some higher order magic.\n\na list in the class to store the instances\na init method to add the instance to the list\na classmethod to get the list of instances\n\nWe can’t just add a _instances = [] statement to the Class, because Pydantic will then assume it is a model field (private attribute). We need to tell Pydantic to ignore the _instances class variable as a model field and treat is as a class variable. Therefore we need to import ClassVar from typing and use it to type the _instances variable.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#enum-classes",
    "href": "classes_db.html#enum-classes",
    "title": "Define Classes and create the SQLite database",
    "section": "Enum Classes",
    "text": "Enum Classes\nFirst we define the possible values of the different variables that are available in the classes. We use the module enum to define Enumerations. We use this to bind the possible values to a variable name, making the code more readable and maintainable.\n\nsource\n\nOrganizationSystem\n\n OrganizationSystem (value, names=None, module=None, qualname=None,\n                     type=None, start=1, boundary=None)\n\nHow tools organize and structure information.\n\nsource\n\n\nPhaseQuality\n\n PhaseQuality (value, names=None, module=None, qualname=None, type=None,\n               start=1, boundary=None)\n\nQuality rating for how well a tool performs in each phase.\n\nsource\n\n\nPhase\n\n Phase (value, names=None, module=None, qualname=None, type=None, start=1,\n        boundary=None)\n\nThe five phases of the PKM workflow.\n\nsource\n\n\nMethod\n\n Method (value, names=None, module=None, qualname=None, type=None,\n         start=1, boundary=None)\n\nHow actions are performed - manually or automatically.\n\nsource\n\n\nInformationType\n\n InformationType (value, names=None, module=None, qualname=None,\n                  type=None, start=1, boundary=None)\n\nInformation content types that flow through the PKM workflow.\n\nPhase(\"refine\")\n\n&lt;Phase.REFINE: 'refine'&gt;",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#pkm-workflow-classes",
    "href": "classes_db.html#pkm-workflow-classes",
    "title": "Define Classes and create the SQLite database",
    "section": "PKM Workflow Classes",
    "text": "PKM Workflow Classes\nNext we create a dataclass for each item we need to be present in the PKM workflow.\nPydantic Dataclasses\nUsed for typechecking.\nWhen creating a new instance for an InformationItem the toolflow must be given as a list of Tool objects. The typechecking makes sure that any Tool object mentioned in the toolfow list, does exist as an actual Tool instance. So make sure to first create all the Tool instances that are needed for an InformationItem, before creating the InformationItem instance.\n\n\n\n\n\n\nTip\n\n\n\nI had some serious trouble getting the Pydantic dataclass validations to work. One of the issues is described above and is about SQLite not supporting all datatypes. A second major issue is that the Pydantic Dataclasses reference each other. The InformationItem references the Tool in the toolflow field. I would also be convenient to store all the InformationItems that can be used with a certain Tool, but in that case we would create a circular reference between InformationItem and Tool.\nWe decided to remove the information_items list from Tool. When we need to get all the InformationItems that are supported by a Tool we can write a Python function or do a SQL-query on the SQLite database.\nBut then we are left with the fact that we want a list of Tools that exist. These are the options considered:\n\ntoolflow: list[Tool]\ntoolflow: list[Tool.name]\ntoolflow: list[str]\n\nThe last option is used in combination with validation to ensure each string is a valid Tool.name.\nHere’s why this is the best approach:\n\nClean serialization (no complex object embedding)\nHuman-readable in the database\nType safety through validation\nEasy to query\n\nThe same goes for the Improvement class and the field tool.\n\n\n\nsource\n\nTool\n\n Tool (id:int|None=None, name:str, description:str|None=None,\n       organization_system:list[__main__.OrganizationSystem],\n       phase_quality:__main__.PhaseQualityData, collect:str|None=None,\n       retrieve:str|None=None, consume:str|None=None,\n       extract:str|None=None, refine:str|None=None)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\n\nsource\n\n\nPhaseQualityData\n\n PhaseQualityData (collect:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   retrieve:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   consume:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   extract:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   refine:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\n\nsource\n\n\nPhaseMethodData\n\n PhaseMethodData (collect:__main__.Method|None=None,\n                  retrieve:__main__.Method|None=None,\n                  consume:__main__.Method|None=None,\n                  extract:__main__.Method|None=None,\n                  refine:__main__.Method|None=None)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\nSince Pydantic v2 Pydantic coerces sequences to tuples with a type of tuple[str, ...] Pydantic will accept a list[str, ...] as a valid input. Therefore we must include both tuple and list as a valid instance int the staticmethod _san. Else the validation will return None if a list is passed which is bad. It should return a TypeError to inform the user to use a tuple or it should just return the values as a tuple. The function _san now returns a tuple of strings if a list is passed.\n\nsource\n\n\nPhaseToolflowData\n\n PhaseToolflowData (collect:Union[str,tuple[str,...],NoneType]=None,\n                    retrieve:Union[str,tuple[str,...],NoneType]=None,\n                    consume:Union[str,tuple[str,...],NoneType]=None,\n                    extract:Union[str,tuple[str,...],NoneType]=None,\n                    refine:Union[str,tuple[str,...],NoneType]=None)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\nExample of creating an instance from PhaseToolflowData with all possible types of input: str, list[str], tuple[str] and just skipping an entry to return None.\n\nPhaseToolflowData(collect=[\"Reader\", \"Recall\"], retrieve=\"Recall\", refine=(\"Obsidian\", \"Recall\"))\n\nPhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume=None, extract=None, refine=('obsidian', 'recall'))\n\n\n\nsource\n\n\nInformationItem\n\n InformationItem (id:int|None=None, name:str,\n                  info_type:__main__.InformationType,\n                  method:__main__.PhaseMethodData,\n                  toolflow:__main__.PhaseToolflowData)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\n\nsource\n\n\nImprovement\n\n Improvement (id:int|None=None, title:str, what:str, why:str, how:str,\n              prio:int, tool:str, phase:__main__.Phase)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\nTest creating instances\n\ndef test_phase_quality_data():\n    pqd = PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT)\n    test_eq(pqd.collect, PhaseQuality.GREAT)\n    test_eq(pqd.retrieve, PhaseQuality.BAD)\n\ndef test_tool_creation():\n    tool = Tool(id=12, name=\"TestTool\", organization_system=[OrganizationSystem.TAGS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n    test_eq(tool.name, \"TestTool\")\n    test_eq(tool.slug, \"testtool\")\n    test_eq(tool.phase_quality.collect, PhaseQuality.GREAT)\n    return tool\n\ndef test_tool_flatten():\n    tool = Tool(id=12, name=\"TestTool\", organization_system=[OrganizationSystem.TAGS, OrganizationSystem.FOLDERS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n    flat = tool.flatten_for_db()\n    test_eq(flat['collect_quality'], 'great')\n    test_eq(flat['retrieve_quality'], 'bad')\n    test_eq(flat['name'], 'TestTool')\n\ndef test_information_item():\n    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n    tools = PhaseToolflowData(collect=\"Reader\", retrieve=(\"Recall\", \"Reader\"), consume=None, extract=None, refine=None)\n    item = InformationItem(id=16, name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n    test_eq(item.method.collect, Method.MANUAL)\n    test_eq(item.toolflow.collect, \"reader\")\n    test_eq(item.toolflow.retrieve, (\"recall\", \"reader\"))\n    return item\n\ndef test_information_item_flatten():\n    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n    tools = PhaseToolflowData(collect=(\"Reader\", \"Recall\"), retrieve=\"Recall\", consume=None, extract=None, refine=None)\n    item = InformationItem(id=16,name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n    flat = item.flatten_for_db()\n    test_eq(flat['collect_method'], 'manual')\n    test_eq(flat['retrieve_method'], None)\n    test_eq(flat['collect_toolflow'], '[\"reader\", \"recall\"]')\n    test_eq(flat['retrieve_toolflow'], 'recall')\n\ndef test_improvement():\n    imp = Improvement(id=18, title=\"Fix Search\", what=\"Better search in Reader\", why=\"Current search is bad\", how=\"By thinking for yoursel\", prio=1, tool=\"testtool\", phase=Phase.RETRIEVE)\n    test_eq(imp.title, \"Fix Search\")\n    test_eq(imp.phase, Phase.RETRIEVE)\n    test_eq(imp.flatten_for_db()['phase'], 'retrieve')\n    return imp\n\n\nOrganizationSystem(\"tags\")\n\n&lt;OrganizationSystem.TAGS: 'tags'&gt;\n\n\n\nOrganizationSystem.FOLDERS\n\n&lt;OrganizationSystem.FOLDERS: 'folders'&gt;\n\n\n\ntest_phase_quality_data()\ntest_tool_creation()\ntest_tool_flatten()\ntest_information_item()\ntest_information_item_flatten()\ntest_improvement()\n\nImprovement(id=18, title='Fix Search', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search')",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#sqlite-database",
    "href": "classes_db.html#sqlite-database",
    "title": "Define Classes and create the SQLite database",
    "section": "SQLite database",
    "text": "SQLite database\n\nCreate and connect\nConnect to the database in the main.py. We should also enable foreign key constraints. These are disabled by default in Sqlite.\nFor testing purposes in this module we will use db = database(\":memory:\") to create an in-memory database.\n\nsource\n\n\ncreate_db\n\n create_db (loc:str='../data/infoflow.db')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nloc\nstr\n../data/infoflow.db\nLocation of the SQLite database\n\n\nReturns\nDatabase\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can add foreign key constraints to the tables using the transform method from sqlite_utils.\ninf_tbl.transform(add_foreign_keys=[(\"&lt;field_name&gt;\", \"&lt;table_name_to_connect&gt;\", \"&lt;field_name_in_table_to_connect&gt;\")])\n\n\nBut for now we won’t use foreign key constraints.\nWe can create the tables using the function create_tables_from_pydantic but we won’t be using it. The tables will be created automatically when we insert the first item for each table.\n\nsource\n\n\ncreate_tables_from_pydantic\n\n create_tables_from_pydantic (db:apswutils.db.Database,\n                              classes:List[pydantic.main.BaseModel])\n\nTests and usage examples\n\ndb = create_db(\":memory:\")\n\n\ncreate_tables_from_pydantic(db, [Tool, InformationItem, Improvement])\n\n\ndb.t\n\nimprovements, information_items, tools\n\n\n\nAdd data to the database\nAdd the created instances to the SQLite tables\n\nTool.get_instances()\n\n{'testtool': Tool(id=12, name='TestTool', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;, &lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='testtool')}\n\n\n\nInformationItem.get_instances()\n\n{'test_article': InformationItem(id=16, name='Test Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume=None, extract=None, refine=None), slug='test_article')}\n\n\nAdd a single instance to the SQLite table\n\ntst = {'name': 'NeoReader', 'collect': None, 'retrieve': None, 'consume': None, 'extract': None, 'refine': None, 'slug': 'neoreader', 'organization_system': '[\"folders\"]', 'collect_quality': 'ok', 'retrieve_quality': 'bad', 'consume_quality': 'great', 'extract_quality': 'na', 'refine_quality': 'na'}\n\n\ndb.t.tools.insert(tst)\n\n{'id': 1,\n 'name': 'NeoReader',\n 'collect': None,\n 'retrieve': None,\n 'consume': None,\n 'extract': None,\n 'refine': None,\n 'slug': 'neoreader',\n 'organization_system': '[\"folders\"]',\n 'collect_quality': 'ok',\n 'retrieve_quality': 'bad',\n 'consume_quality': 'great',\n 'extract_quality': 'na',\n 'refine_quality': 'na'}\n\n\n\ntst2 = {'id': 1, 'name': 'NeoReader', 'collect': \"hiers staat nu wat\", 'retrieve': None, 'consume': None, 'extract': None, 'refine': None, 'slug': 'neoreader', 'organization_system': '[\"folders\"]', 'collect_quality': 'ok', 'retrieve_quality': 'bad', 'consume_quality': 'great', 'extract_quality': 'na', 'refine_quality': 'na'}\n\n\ndb.t.tools.update(tst2)\n\n{'id': 1,\n 'name': 'NeoReader',\n 'collect': 'hiers staat nu wat',\n 'retrieve': None,\n 'consume': None,\n 'extract': None,\n 'refine': None,\n 'slug': 'neoreader',\n 'organization_system': '[\"folders\"]',\n 'collect_quality': 'ok',\n 'retrieve_quality': 'bad',\n 'consume_quality': 'great',\n 'extract_quality': 'na',\n 'refine_quality': 'na'}\n\n\n\ndb.t.improvements.insert(Improvement.get_instances()['fix_search'].flatten_for_db())\ndb.t.information_items.insert(InformationItem.get_instances()['test_article'].flatten_for_db())\n\n{'id': 16,\n 'name': 'Test Article',\n 'info_type': 'web_article',\n 'slug': 'test_article',\n 'collect_method': 'manual',\n 'retrieve_method': None,\n 'consume_method': None,\n 'extract_method': None,\n 'refine_method': None,\n 'collect_toolflow': '[\"reader\", \"recall\"]',\n 'retrieve_toolflow': 'recall',\n 'consume_toolflow': None,\n 'extract_toolflow': None,\n 'refine_toolflow': None}\n\n\n\n[r for r in db.t.information_items.rows_where()]\n\n[{'id': 16,\n  'name': 'Test Article',\n  'info_type': 'web_article',\n  'slug': 'test_article',\n  'collect_method': 'manual',\n  'retrieve_method': None,\n  'consume_method': None,\n  'extract_method': None,\n  'refine_method': None,\n  'collect_toolflow': '[\"reader\", \"recall\"]',\n  'retrieve_toolflow': 'recall',\n  'consume_toolflow': None,\n  'extract_toolflow': None,\n  'refine_toolflow': None}]\n\n\nAdd multiple instances to the SQLite table\n\ndb.t.tools.insert_all([t.flatten_for_db() for t in Tool.get_instances().values()])\n\n&lt;Table tools (id, name, collect, retrieve, consume, extract, refine, slug, organization_system, collect_quality, retrieve_quality, consume_quality, extract_quality, refine_quality)&gt;\n\n\n\n[t.flatten_for_db() for t in Tool.get_instances().values()]\n\n[{'id': 12,\n  'name': 'TestTool',\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\n[r for r in db.t.tools.rows]\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\n\nRetrieve data from the database\nNow retrieve the info from the database as intances from the Pydantic Dataclass using the MiniDataAPI from answer.ai.\n\ntype(db.t.tools)\n\napswutils.db.Table\n\n\n\ndb.t.tools()\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\ntool = Tool.from_db(db.t.tools()[0])\ntool\n\nTool(id=1, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect='hiers staat nu wat', retrieve=None, consume=None, extract=None, refine=None, slug='neoreader')\n\n\n\ndb.t.tools()\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\nsource\n\n\n\ndict_from_db\n\n dict_from_db (db_table:apswutils.db.Table,\n               class_table:pydantic.main.BaseModel)\n\nConverts a database table to a dictionary of pydantic models.\n\ntools_dict = dict_from_db(db.t.tools, Tool)\nitem_dict = dict_from_db(db.t.information_items, InformationItem)\n\n\ntools_dict\n\n{'neoreader': Tool(id=1, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect='hiers staat nu wat', retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'testtool': Tool(id=12, name='TestTool', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;, &lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='testtool')}",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "create_webapp.html",
    "href": "create_webapp.html",
    "title": "Create the webapplication logic and visualisations",
    "section": "",
    "text": "The web-application will show on the main page the information flow as created by the create_combined_infoflow_viz from the infoflow.viz module. This function returns a graphviz.graphs.Digraph object. We turn this object into a SVG string which we can then modify to create clickable nodes. To make this possible we need several steps:\n\nCreate the infoflow graph, see Create the vizualisation\nConvert the graph to an SVG string, see Create the vizualisation\nCreate a dictionary from all the nodes in the graph\nUse that dictionary to alter the SVG string to create clickable nodes\nCreate the main page from the web-application that shows the information flow as an SVG image.\nCreate a function to make a webpage for every element in the infoflow.\n\n\nAd. 4.\nWe could also create this dictionary from the instances we made from all the elements in our infoflow. The same instances that are use to create the graph in the first place. But I choose to create the dictionary from the SVG-string from the Digraph object, becaust then I will be able to use that function to create clickable SVG images from other sources as well.",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#stucture-of-the-web-application",
    "href": "create_webapp.html#stucture-of-the-web-application",
    "title": "Create the webapplication logic and visualisations",
    "section": "",
    "text": "The web-application will show on the main page the information flow as created by the create_combined_infoflow_viz from the infoflow.viz module. This function returns a graphviz.graphs.Digraph object. We turn this object into a SVG string which we can then modify to create clickable nodes. To make this possible we need several steps:\n\nCreate the infoflow graph, see Create the vizualisation\nConvert the graph to an SVG string, see Create the vizualisation\nCreate a dictionary from all the nodes in the graph\nUse that dictionary to alter the SVG string to create clickable nodes\nCreate the main page from the web-application that shows the information flow as an SVG image.\nCreate a function to make a webpage for every element in the infoflow.\n\n\nAd. 4.\nWe could also create this dictionary from the instances we made from all the elements in our infoflow. The same instances that are use to create the graph in the first place. But I choose to create the dictionary from the SVG-string from the Digraph object, becaust then I will be able to use that function to create clickable SVG images from other sources as well.",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#background-information-on-building-the-clickable-information-flow-visualisation-in-a-fasthtml-web-application",
    "href": "create_webapp.html#background-information-on-building-the-clickable-information-flow-visualisation-in-a-fasthtml-web-application",
    "title": "Create the webapplication logic and visualisations",
    "section": "Background information on building the clickable information flow visualisation in a FastHTML web-application",
    "text": "Background information on building the clickable information flow visualisation in a FastHTML web-application\n\nHow to visualize a SVG string in a webapp\nUse NotStr() to prevent HTML escaping of the SVG string.\n\nsvg_sample = \"\"\"&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\\n&lt;!-- Generated by graphviz version 2.43.0 (0)\\n --&gt;\\n&lt;!-- Title: %3 Pages: 1 --&gt;\\n&lt;svg width=\"226pt\" height=\"534pt\"\\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\\n&lt;title&gt;%3&lt;/title&gt;\\n&lt;polygon fill=\"transparent\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\\n&lt;!-- neoreader_collect --&gt;\\n&lt;g id=\"node1\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_collect&lt;/title&gt;\\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve --&gt;\\n&lt;g id=\"node2\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\\n&lt;g id=\"edge2\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume --&gt;\\n&lt;g id=\"node3\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_consume&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\\n&lt;g id=\"edge3\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract --&gt;\\n&lt;g id=\"node4\" class=\"node\"&gt;\\n&lt;title&gt;readwise_extract&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\\n&lt;g id=\"edge4\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- obsidian_refine --&gt;\\n&lt;g id=\"node5\" class=\"node\"&gt;\\n&lt;title&gt;obsidian_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\\n&lt;g id=\"edge5\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- recall_refine --&gt;\\n&lt;g id=\"node6\" class=\"node\"&gt;\\n&lt;title&gt;recall_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\\n&lt;g id=\"edge6\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document --&gt;\\n&lt;g id=\"node7\" class=\"node\"&gt;\\n&lt;title&gt;source_document&lt;/title&gt;\\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\\n&lt;g id=\"edge1\" class=\"edge\"&gt;\\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\\n&lt;/g&gt;\\n&lt;/g&gt;\\n&lt;/svg&gt;\\n\"\"\"\n\n\nprint(svg_sample)\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;!-- Generated by graphviz version 2.43.0 (0)\n --&gt;\n&lt;!-- Title: %3 Pages: 1 --&gt;\n&lt;svg width=\"226pt\" height=\"534pt\"\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\n&lt;title&gt;%3&lt;/title&gt;\n&lt;polygon fill=\"transparent\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\n&lt;!-- neoreader_collect --&gt;\n&lt;g id=\"node1\" class=\"node\"&gt;\n&lt;title&gt;neoreader_collect&lt;/title&gt;\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_retrieve --&gt;\n&lt;g id=\"node2\" class=\"node\"&gt;\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\n&lt;g id=\"edge2\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_consume --&gt;\n&lt;g id=\"node3\" class=\"node\"&gt;\n&lt;title&gt;neoreader_consume&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\n&lt;g id=\"edge3\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract --&gt;\n&lt;g id=\"node4\" class=\"node\"&gt;\n&lt;title&gt;readwise_extract&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\n&lt;g id=\"edge4\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\n&lt;/g&gt;\n&lt;!-- obsidian_refine --&gt;\n&lt;g id=\"node5\" class=\"node\"&gt;\n&lt;title&gt;obsidian_refine&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\n&lt;g id=\"edge5\" class=\"edge\"&gt;\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\n&lt;/g&gt;\n&lt;!-- recall_refine --&gt;\n&lt;g id=\"node6\" class=\"node\"&gt;\n&lt;title&gt;recall_refine&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\n&lt;g id=\"edge6\" class=\"edge\"&gt;\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\n&lt;/g&gt;\n&lt;!-- source_document --&gt;\n&lt;g id=\"node7\" class=\"node\"&gt;\n&lt;title&gt;source_document&lt;/title&gt;\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\n&lt;g id=\"edge1\" class=\"edge\"&gt;\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\n\n\n\n\nshow(Div(NotStr(svg_sample)))\n\n\n\n\n\n\n\n%3\n\n\n\nneoreader_collect\n\nNeoReader\n(collect)\n\n\n\nneoreader_retrieve\n\nNeoReader\n(retrieve)\n\n\n\nneoreader_collect-&gt;neoreader_retrieve\n\n\n\n\n\nneoreader_consume\n\nNeoReader\n(consume)\n\n\n\nneoreader_retrieve-&gt;neoreader_consume\n\n\n\n\n\nreadwise_extract\n\nReadwise\n(extract)\n\n\n\nneoreader_consume-&gt;readwise_extract\n\n\n\n\n\nobsidian_refine\n\nObsidian\n(refine)\n\n\n\nreadwise_extract-&gt;obsidian_refine\n\n\n\n\n\nrecall_refine\n\nRecall\n(refine)\n\n\n\nreadwise_extract-&gt;recall_refine\n\n\n\n\n\nsource_document\n\nDocument\n\n\n\nsource_document-&gt;neoreader_collect\n\n\n\n\n\n\n\n\n\n\nHow to make a node from the Digraph SVG-string clickable in FastHTML\n\nAdd onclick handlers with htmx.ajax calls to the  elements you want clickable\nInclude a target div (#content-area) where content will be swapped\nAdd a CSS style attribute so the pointer cursor changes to a hand when hovering over the node\n\nFor example you can add this to the  element of the node you want clickable:\nonclick=\"htmx.ajax('GET', '/recall-retrieve', {target: '#content-area', swap: 'outerHTML'})\"\nstyle=\"cursor: pointer;\"\nBut a more concise way is to add CSS styling to the FastHTML app that targets all nodes:\n.node { cursor: pointer; }\nThat is what we will be using in this application.\nBelow is an example of a SVG-string with a clickable node that shows a changing pointer cursor when hovering over it.\n\nsvg_sample_click = \"\"\"&lt;svg width=\"268pt\" height=\"338pt\" viewBox=\"0.00 0.00 267.84 338.16\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 334.16)\"&gt;\n&lt;polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-334.16 263.84,-334.16 263.84,4 -4,4\"/&gt;\n&lt;g id=\"node3\" class=\"node\" onclick=\"htmx.ajax('GET', '/recall-retrieve', {target: '#content-area', swap: 'outerHTML'})\" style=\"cursor: pointer;\"&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"198.09,-129.08 163.76,-160.13 95.08,-160.13 60.75,-129.08 95.08,-98.03 163.76,-98.03 198.09,-129.08\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"129.42\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"129.42\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\"\"\"\n\nThe below example can’t be clicked, because it is not running on a webserver and the GET request will also fail, because the endpoint doesn’t exist yet. But it does show how the pointer changes.\n\nshow(Div(NotStr(svg_sample_click), id=\"content-area\"))\n\n\n\n\n\n\nRecall\n(retrieve)",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#create-a-dictionary-from-all-the-nodes-in-the-graph",
    "href": "create_webapp.html#create-a-dictionary-from-all-the-nodes-in-the-graph",
    "title": "Create the webapplication logic and visualisations",
    "section": "Create a dictionary from all the nodes in the graph",
    "text": "Create a dictionary from all the nodes in the graph\nThe SVG-string is an XML string. I considered several ways to parse XML string:\n\nBeautifulSoup\nminidom from xml.dom\nxml.etree.ElementTree\n\nI choose the latest because it is simpler than minidom from xml.dom. The main advantage of xml.dom is that it supports complete DOM operations. But that isn’t needed in this application. BeautifulSoup is propably more forgiving and versatile than xml.etree.ElementTree, but ElementTree is more than enough for this application and does not add another dependency.\nWe only look for node elements in the root of the XML string. We also skip the edge elements.\n\nsource\n\ndict_svgnodes\n\n dict_svgnodes (svg_str:str)\n\nExample usage of dict_svgnodes()\n\nnds_dict = dict_svgnodes(svg_sample)\npprint(nds_dict)\n\n{'neoreader_collect': {'class': 'node',\n                       'fill': 'lightblue',\n                       'id': 'node1',\n                       'stroke': 'black',\n                       'text': ['NeoReader', '(collect)']},\n 'neoreader_consume': {'class': 'node',\n                       'fill': 'lightgreen',\n                       'id': 'node3',\n                       'stroke': 'black',\n                       'text': ['NeoReader', '(consume)']},\n 'neoreader_retrieve': {'class': 'node',\n                        'fill': 'orange',\n                        'id': 'node2',\n                        'stroke': 'black',\n                        'text': ['NeoReader', '(retrieve)']},\n 'obsidian_refine': {'class': 'node',\n                     'fill': 'lightgreen',\n                     'id': 'node5',\n                     'stroke': 'black',\n                     'text': ['Obsidian', '(refine)']},\n 'readwise_extract': {'class': 'node',\n                      'fill': 'lightgreen',\n                      'id': 'node4',\n                      'stroke': 'black',\n                      'text': ['Readwise', '(extract)']},\n 'recall_refine': {'class': 'node',\n                   'fill': 'lightgreen',\n                   'id': 'node6',\n                   'stroke': 'black',\n                   'text': ['Recall', '(refine)']},\n 'source_document': {'class': 'node',\n                     'fill': 'none',\n                     'id': 'node7',\n                     'stroke': 'black',\n                     'text': ['Document']}}",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#create-clickable-nodes-in-the-svg-string",
    "href": "create_webapp.html#create-clickable-nodes-in-the-svg-string",
    "title": "Create the webapplication logic and visualisations",
    "section": "Create clickable nodes in the SVG string",
    "text": "Create clickable nodes in the SVG string\n\nsource\n\nadd_onclick_to_nodes\n\n add_onclick_to_nodes (svg_str:str)\n\nExample usage and test\n\nsvg_clickable = add_onclick_to_nodes(svg_sample)\n\n\nsvg_clickable\n\n'&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\\n&lt;!-- Generated by graphviz version 2.43.0 (0)\\n --&gt;\\n&lt;!-- Title: %3 Pages: 1 --&gt;\\n&lt;svg width=\"226pt\" height=\"534pt\"\\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\\n&lt;title&gt;%3&lt;/title&gt;\\n&lt;polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\\n&lt;!-- neoreader_collect --&gt;\\n&lt;g id=\"node1\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_collect&lt;/title&gt;\\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve --&gt;\\n&lt;g id=\"node2\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\\n&lt;g id=\"edge2\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume --&gt;\\n&lt;g id=\"node3\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_consume&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\\n&lt;g id=\"edge3\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract --&gt;\\n&lt;g id=\"node4\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=readwise\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;readwise_extract&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\\n&lt;g id=\"edge4\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- obsidian_refine --&gt;\\n&lt;g id=\"node5\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=obsidian\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;obsidian_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\\n&lt;g id=\"edge5\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- recall_refine --&gt;\\n&lt;g id=\"node6\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=recall\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;recall_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\\n&lt;g id=\"edge6\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document --&gt;\\n&lt;g id=\"node7\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/resource?slug=document\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;source_document&lt;/title&gt;\\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\\n&lt;g id=\"edge1\" class=\"edge\"&gt;\\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\\n&lt;/g&gt;\\n&lt;/g&gt;\\n&lt;/svg&gt;\\n'\n\n\n\nshow(Div(NotStr(svg_clickable)))\n\n\n\n\n\n\n\n%3\n\n\n\nneoreader_collect\n\nNeoReader\n(collect)\n\n\n\nneoreader_retrieve\n\nNeoReader\n(retrieve)\n\n\n\nneoreader_collect-&gt;neoreader_retrieve\n\n\n\n\n\nneoreader_consume\n\nNeoReader\n(consume)\n\n\n\nneoreader_retrieve-&gt;neoreader_consume\n\n\n\n\n\nreadwise_extract\n\nReadwise\n(extract)\n\n\n\nneoreader_consume-&gt;readwise_extract\n\n\n\n\n\nobsidian_refine\n\nObsidian\n(refine)\n\n\n\nreadwise_extract-&gt;obsidian_refine\n\n\n\n\n\nrecall_refine\n\nRecall\n(refine)\n\n\n\nreadwise_extract-&gt;recall_refine\n\n\n\n\n\nsource_document\n\nDocument\n\n\n\nsource_document-&gt;neoreader_collect\n\n\n\n\n\n\n\n\n\ntest(svg_clickable, \"Reader\", operator.contains) # Check if the node name is in the svg string\ntest(svg_clickable, \"onclick\", operator.contains) # Check if the onclick attribute is in the svg string\ntest(svg_clickable, \"#main-content\", operator.contains) # Check if the id is in the svg string\ntest(svg_clickable, \"&lt;svg width=\", operator.contains) # Check if the svg tag is in the svg string\ntest(svg_clickable, \"xmlns\", operator.contains) # Check if the xmlns attribute is in the svg string",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_instances.html",
    "href": "create_instances.html",
    "title": "Create Instances",
    "section": "",
    "text": "# TODO: Maybe we don't need this file. We can use the app to create instances and place those in the database.",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_instances.html#tools",
    "href": "create_instances.html#tools",
    "title": "Create Instances",
    "section": "Tools",
    "text": "Tools\nThe function tools_from_code can be used to create instances for every Tool available. The instances are hardcoded in the function. This function can be used to start a fresh database.\nThe function tools_from_db can be used to create instances for every Tool available in the database.\nIn both cases the function does not return anything. The available instances are tracked in the Tool class and can be retrieved as a list using the get_instances method on the Tool class.\nWe must start with creating instances for each Tool that we can use. This must be done before we can create instances for the InformationItem and Improvement classes, because both have fields that are validated against the field name in the Tool class.\n\nsource\n\ntools_from_code\n\n tools_from_code ()\n\nCreate all Tool instances as defined in the code.\nThe next stap is to define instances for each InformationItem we have.\n\ntools_from_code()\nTool.get_instances()\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_instances.html#informationitems",
    "href": "create_instances.html#informationitems",
    "title": "Create Instances",
    "section": "InformationItems",
    "text": "InformationItems\nJust as with the Tools we have two functions to create instances for every InformationItem. We can use the function informationitems_from_code to create instances for every InformationItem available from the definitions hardcoded in the function. This function can be used to start a fresh database. We can use the function informationitems_from_db to create instances for every InformationItem available in the database.\nThese functions don’t return anything. The available instances are tracked in the InformationItem class and can be retrieved as a list using the get_instances method on the InformationItem class.\n\nsource\n\ninformationitems_from_code\n\n informationitems_from_code ()\n\nCreate all InformationItem instances as defined in the code.\nCheck all the available tools and information items.\n\ninformationitems_from_code()\n\n\nInformationItem.get_instances()\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_vizualisation.html",
    "href": "create_vizualisation.html",
    "title": "Create graphiz visualisation",
    "section": "",
    "text": "tools_from_code()\ninformationitems_from_code()\n\n\ntools_inst = Tool.get_instances()\nitems_inst = InformationItem.get_instances()\n\n\ntools_inst\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\n\nitems_inst\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}\n\n\n\ntest_eq(len(items_inst), 8)\ntest(tools_inst, \"reader\", operator.contains)",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#creating-some-instances-for-testing",
    "href": "create_vizualisation.html#creating-some-instances-for-testing",
    "title": "Create graphiz visualisation",
    "section": "",
    "text": "tools_from_code()\ninformationitems_from_code()\n\n\ntools_inst = Tool.get_instances()\nitems_inst = InformationItem.get_instances()\n\n\ntools_inst\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\n\nitems_inst\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}\n\n\n\ntest_eq(len(items_inst), 8)\ntest(tools_inst, \"reader\", operator.contains)",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#helper-functions",
    "href": "create_vizualisation.html#helper-functions",
    "title": "Create graphiz visualisation",
    "section": "Helper functions",
    "text": "Helper functions\nThe function get_items_for_tool filters all the instances of the class InformationItem based on which information items can be processed by the given tool.\n\nsource\n\nget_info_items_for_tool\n\n get_info_items_for_tool (tool_name:str,\n                          info_items:dict[infoflow.classdb.InformationItem\n                          ])\n\nFilters all the instances of the class InformationItem based on which information items can be processed by the given tool.\nTest the get_info_items_for_tool function.\n\nget_info_items_for_tool('reader', items_inst)\n\n{'Web Article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article')}",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#graphiz-visualisation",
    "href": "create_vizualisation.html#graphiz-visualisation",
    "title": "Create graphiz visualisation",
    "section": "Graphiz visualisation",
    "text": "Graphiz visualisation\nThe function to create the workflow visualisation for the given info_items and tools. This is done in two steps. First we use the function create_workflow_viz that functions as a wrapper around the build_graphiz_from_instances function.\nThe create_workflow_viz has two tasks:\n\nIt makes calling the build_graphiz_from_instances function easier by assuming we want to use all instances from the Tool and InformationItem classes. If we want to use a single instance, we can pass a single instance of Tool or InformationItem. If we want several, but not all, instances of Tool or InformationItem, we can pass a dict of instances.\nIt adds the option to filter the graph to be created on a single Tool-name. If the parameter tool_filter is used, the function calls the get_info_items_for_tool function and filters the needed InformationItem instances based on that tool. This way only those parts of the graph will be drawn that we want to see.\n\n\nsource\n\nbuild_graphiz_from_intances\n\n build_graphiz_from_intances (info_items, tools)\n\nCreate a graphviz visualisation using the updated dataclasses for InformationItem and Tool. Produces the same layout as build_graphiz_from_instances.\n\nsource\n\n\ncreate_workflow_viz\n\n create_workflow_viz (items:infoflow.classdb.InformationItem|dict[str,info\n                      flow.classdb.InformationItem], tools:infoflow.classd\n                      b.Tool|dict[str,infoflow.classdb.Tool],\n                      tool_filter:None|str=None)\n\nCreate workflow visualization with flexible filtering options.\n\nTool.get_instances()\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\nAn example for creating the actual visualisation for the given info_items and tools.\n\nviz = create_workflow_viz(items_inst, tools_inst)\ntype(viz)\n\ngraphviz.graphs.Digraph\n\n\n\nviz\n\n\n\n\n\n\n\n\n\nviz_document = create_workflow_viz(items_inst['research_paper'], tools_inst)\nviz_document\n\n\n\n\n\n\n\n\n\nviz_tool = create_workflow_viz(items_inst, tools_inst, tool_filter='neoreader')\nviz_tool\n\n\n\n\n\n\n\n\nTo get the SVG output, you can use the _repr_image_svg_xml method of the Digraph object. Below is an example showing the first 200 characters.\n\nprint(viz._repr_image_svg_xml()[:600])\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;!-- Generated by graphviz version 2.43.0 (0)\n --&gt;\n&lt;!-- Title: %3 Pages: 1 --&gt;\n&lt;svg width=\"956pt\" height=\"534pt\"\n viewBox=\"0.00 0.00 956.04 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\n&lt;title&gt;%3&lt;/title&gt;\n&lt;!-- reader_collect --&gt;\n&lt;g id=\"node1\" class=\"node\"&gt;\n&lt;title&gt;reader_collect&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "infoflow",
    "section": "",
    "text": "I created this project because I want a personal knowledge management system to efficiently collect, organize, and retrieve information from various sources (books, articles, videos, podcasts, research papers, etc.). I usually can’t immediately consume the information I encounter. By building a clear workflow of actions and tools I use to solve the problem of having more interesting information than I can process. By creating a structured four-phase workflow (Collect, Retrieve, Consume, Refine) I aim to make it as easy and fast as possible to store items when I encounter them and later find relevant information when I need it based on my current interests or projects.\nI want to implement this as Python classes and visualize it with Graphviz because this approach provides flexibility to easily modify tools and processes, unlike static text or diagram-based approaches.\n\n\n\ncd {folder where you want to create the folder for this project}\ngit clone git@github.com:Hopsakee/infoflow.git\ncd infoflow\nuv sync\nuv run main.py\nThis starts a local server where the application will be run.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#user-guide",
    "href": "index.html#user-guide",
    "title": "infoflow",
    "section": "",
    "text": "I created this project because I want a personal knowledge management system to efficiently collect, organize, and retrieve information from various sources (books, articles, videos, podcasts, research papers, etc.). I usually can’t immediately consume the information I encounter. By building a clear workflow of actions and tools I use to solve the problem of having more interesting information than I can process. By creating a structured four-phase workflow (Collect, Retrieve, Consume, Refine) I aim to make it as easy and fast as possible to store items when I encounter them and later find relevant information when I need it based on my current interests or projects.\nI want to implement this as Python classes and visualize it with Graphviz because this approach provides flexibility to easily modify tools and processes, unlike static text or diagram-based approaches.\n\n\n\ncd {folder where you want to create the folder for this project}\ngit clone git@github.com:Hopsakee/infoflow.git\ncd infoflow\nuv sync\nuv run main.py\nThis starts a local server where the application will be run.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "infoflow",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall infoflow in Development mode\n# make sure infoflow package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to infoflow\n$ nbdev_prepare",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "infoflow",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/Hopsakee/infoflow.git\nor from conda\n$ conda install -c Hopsakee infoflow\nor from pypi\n$ pip install infoflow\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "infoflow",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "infoflow"
    ]
  }
]
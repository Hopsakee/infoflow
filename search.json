[
  {
    "objectID": "classes_db.html",
    "href": "classes_db.html",
    "title": "Define Classes and create the SQLite database",
    "section": "",
    "text": "We use from __future__ import annotations to support forward references in type hints. To be precise in the @classmethod we create to keep track of all instances of the class.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#using-pydantic-with-minidataapi-and-sqlite",
    "href": "classes_db.html#using-pydantic-with-minidataapi-and-sqlite",
    "title": "Define Classes and create the SQLite database",
    "section": "Using Pydantic with MiniDataAPI and SQLite",
    "text": "Using Pydantic with MiniDataAPI and SQLite\nWe want to use Pydantic Dataclasses to enable typechecking and validation. We also want to use the Dataclasses with the MiniDataAPI to create the tables in the SQLite database. But SQLite only has datatypes: NULL, INTEGER, REAL, TEXT, and BLOB. So no list or any of the Dataclass(Enum) types we use.\nTo be able to use both Pydanctic and the MiniDataAPI we will do two things:\n\nDefine a Pydantic Dataclass with the correct datatypes and a Dataclass that has the same fields as the Pydantic Dataclass, but with datatypes that can be used with SQLite.\nWe add @field_serializer methods to the Pydantic Dataclass that convert the fields to JSON strings when we use the method .model_dump() on the instance of the Pydantic Dataclass. These serialised JSON strings can then be added to the SQLite database.\nWe also use the @field_validator decorator to convert the JSON strings back to the correct datatypes when we load the data from the SQLite database back into the Pydantic Dataclass.\n\nThis way we can:\n\ncreate instances with the Pydantic Dataclass to have easy typechecking and validation.\nconvert this instances to MiniDataAPI and SQLite friendly datatypes using .model_dump() on the instance, that we can then add to the database.\nload the data from the SQLite database back into the Pydantic Dataclass.\n\nThe exact implementation can be found below where the Classes are defined.\n\nTrack instances of classes\nWe also want to keep track of the instances available for each class. Therefore we need some higher order magic.\n\na list in the class to store the instances\na init method to add the instance to the list\na classmethod to get the list of instances\n\nWe can’t just add a _instances = [] statement to the Class, because Pydantic will then assume it is a model field (private attribute). We need to tell Pydantic to ignore the _instances class variable as a model field and treat is as a class variable. Therefore we need to import ClassVar from typing and use it to type the _instances variable.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#enum-classes",
    "href": "classes_db.html#enum-classes",
    "title": "Define Classes and create the SQLite database",
    "section": "Enum Classes",
    "text": "Enum Classes\nFirst we define the possible values of the different variables that are available in the classes. We use the module enum to define Enumerations. We use this to bind the possible values to a variable name, making the code more readable and maintainable.\n\nsource\n\nOrganizationSystem\n\n OrganizationSystem (value, names=None, module=None, qualname=None,\n                     type=None, start=1, boundary=None)\n\nHow tools organize and structure information.\n\nsource\n\n\nPhaseQuality\n\n PhaseQuality (value, names=None, module=None, qualname=None, type=None,\n               start=1, boundary=None)\n\nQuality rating for how well a tool performs in each phase.\n\nsource\n\n\nPhase\n\n Phase (value, names=None, module=None, qualname=None, type=None, start=1,\n        boundary=None)\n\nThe five phases of the PKM workflow.\n\nsource\n\n\nMethod\n\n Method (value, names=None, module=None, qualname=None, type=None,\n         start=1, boundary=None)\n\nHow actions are performed - manually or automatically.\n\nsource\n\n\nInformationType\n\n InformationType (value, names=None, module=None, qualname=None,\n                  type=None, start=1, boundary=None)\n\nInformation content types that flow through the PKM workflow.\n\nPhase(\"refine\")\n\n&lt;Phase.REFINE: 'refine'&gt;",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#base-class-to-use-for-database-classes",
    "href": "classes_db.html#base-class-to-use-for-database-classes",
    "title": "Define Classes and create the SQLite database",
    "section": "Base class to use for database classes",
    "text": "Base class to use for database classes\n\nsource\n\nSluggedModel\n\n SluggedModel ()\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#pkm-workflow-classes",
    "href": "classes_db.html#pkm-workflow-classes",
    "title": "Define Classes and create the SQLite database",
    "section": "PKM Workflow Classes",
    "text": "PKM Workflow Classes\nNext we create a dataclass for each item we need to be present in the PKM workflow.\nPydantic Dataclasses\nUsed for typechecking.\nWhen creating a new instance for an InformationItem the toolflow must be given as a list of Tool objects. The typechecking makes sure that any Tool object mentioned in the toolfow list, does exist as an actual Tool instance. So make sure to first create all the Tool instances that are needed for an InformationItem, before creating the InformationItem instance.\n\n\n\n\n\n\nTip\n\n\n\nI had some serious trouble getting the Pydantic dataclass validations to work. One of the issues is described above and is about SQLite not supporting all datatypes. A second major issue is that the Pydantic Dataclasses reference each other. The InformationItem references the Tool in the toolflow field. I would also be convenient to store all the InformationItems that can be used with a certain Tool, but in that case we would create a circular reference between InformationItem and Tool.\nWe decided to remove the information_items list from Tool. When we need to get all the InformationItems that are supported by a Tool we can write a Python function or do a SQL-query on the SQLite database.\nBut then we are left with the fact that we want a list of Tools that exist. These are the options considered:\n\ntoolflow: list[Tool]\ntoolflow: list[Tool.name]\ntoolflow: list[str]\n\nThe last option is used in combination with validation to ensure each string is a valid Tool.name.\nHere’s why this is the best approach:\n\nClean serialization (no complex object embedding)\nHuman-readable in the database\nType safety through validation\nEasy to query\n\nThe same goes for the Improvement class and the field tool.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#explainer-for-the-pydantic-dataclass-tool",
    "href": "classes_db.html#explainer-for-the-pydantic-dataclass-tool",
    "title": "Define Classes and create the SQLite database",
    "section": "Explainer for the Pydantic Dataclass Tool",
    "text": "Explainer for the Pydantic Dataclass Tool\n\nMethod Tool.from_db\n@classmethod\ndef from_db(cls, db_record):\n    phase_quality = PhaseQualityData(\n        collect=PhaseQuality(db_record['collect_quality']),\n        retrieve=PhaseQuality(db_record['retrieve_quality']),\n        consume=PhaseQuality(db_record['consume_quality']),\n        extract=PhaseQuality(db_record['extract_quality']),\n        refine=PhaseQuality(db_record['refine_quality'])\n    )\n    org_systems = [OrganizationSystem(s) for s in json.loads(db_record['organization_system'])]\n    return cls(\n        id=db_record['id'],\n        name=db_record['name'],\n        description=db_record.get('description'),\n        organization_system=org_systems,\n        phase_quality=phase_quality,\n        collect=db_record['collect'],\n        retrieve=db_record['retrieve'],\n        consume=db_record['consume'],\n        extract=db_record['extract'],\n        refine=db_record['refine']\n    )\n\nInput: db_record is a row from the Tools table (e.g. a dict-like object from fastlite).\nRebuild phase_quality:\n\nDB stores each quality as a string ('na' | 'bad' | 'ok' | 'great').\nPhaseQualityData is reconstructed by wrapping each DB value with the PhaseQuality enum.\n\nRebuild organization_system:\n\nDB stores it as a JSON string representing a list of enum values, e.g. [\"tags\",\"folders\"].\njson.loads turns that into a Python list of strings.\nEach string is turned into an OrganizationSystem enum instance.\n\nInstantiate Tool:\n\nPass all the primitive fields straight from db_record.\nPass the reconstructed phase_quality and organization_system.\n\nSide-effect:\n\ninit registers the instance in Tool._instances keyed by slug.\n\n\nIn short: from_db converts DB‑friendly fields (JSON/string) back into enum-rich, structured Pydantic objects.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#informationitem.from_db",
    "href": "classes_db.html#informationitem.from_db",
    "title": "Define Classes and create the SQLite database",
    "section": "2. InformationItem.from_db",
    "text": "2. InformationItem.from_db\n@classmethod\ndef from_db(cls, db_record):\n    toolflow = PhaseToolflowData(\n        collect=cls._parse_toolflow(db_record['collect_toolflow']),\n        retrieve=cls._parse_toolflow(db_record['retrieve_toolflow']),\n        consume=cls._parse_toolflow(db_record['consume_toolflow']),\n        extract=cls._parse_toolflow(db_record['extract_toolflow']),\n        refine=cls._parse_toolflow(db_record['refine_toolflow'])\n    )\n    method = PhaseMethodData(\n        collect=db_record['collect_method'],\n        retrieve=db_record['retrieve_method'],\n        consume=db_record['consume_method'],\n        extract=db_record['extract_method'],\n        refine=db_record['refine_method']\n    )\n    info_type = InformationType(db_record['info_type'])\n    return cls(\n        id=db_record['id'],\n        name=db_record['name'],\n        info_type=info_type,\n        method=method,\n        toolflow=toolflow\n    )\nThe helper:\n@staticmethod\ndef _parse_toolflow(v):\n    if v is None: return None\n    if isinstance(v, str) and v.startswith('['): return json.loads(v)\n    return v\n\nInput: a row from InformationItems.\nRebuild toolflow:\n\nDB stores each *_toolflow as either:\n\nNULL/None,\na plain string (single tool),\nor a JSON-encoded list (multiple tools).\n\n_parse_toolflow:\n\nreturns None for None,\njson.loads if it looks like a JSON list (starts with '['),\notherwise leaves the string as‑is.\n\nThose values feed into PhaseToolflowData (which itself sanitizes names via validators).\n\nRebuild method:\n\nNote: DB stores method values as strings (\"manual\", \"automatic\", \"na\" or None).\nPhaseMethodData fields are annotated as Method | None, so Pydantic will convert those strings to Method enums automatically.\n\nRebuild info_type:\n\nDB stores info_type as its string value (e.g. \"book\").\nThis is wrapped into InformationType.\n\nInstantiate InformationItem:\n\nPass the reconstructed info_type, method, toolflow, plus id and name.\ninit adds the instance to InformationItem._instances.\n\n\nIn short: from_db reverses the flattening that turned nested structures (PhaseMethodData, PhaseToolflowData, InformationType) into many DB columns + JSON strings.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#improvement.from_db",
    "href": "classes_db.html#improvement.from_db",
    "title": "Define Classes and create the SQLite database",
    "section": "3. Improvement.from_db",
    "text": "3. Improvement.from_db\n@classmethod\ndef from_db(cls, db_record):\n    phase = Phase(db_record['phase'])\n    return cls(\n        id=db_record['id'],\n        title=db_record['title'],\n        what=db_record['what'],\n        why=db_record['why'],\n        prio=db_record['prio'],\n        tool=db_record['tool'],\n        phase=phase\n    )\n\nInput: a row from Improvements.\nRebuild phase:\n\nDB stores phase as a string (e.g. \"collect\").\nWrap in the Phase enum.\n\nInstantiate Improvement:\n\nAll other fields are passed through as-is.\ninit registers in Improvement._instances.\ntool will be validated against Tool.get_instances() by the field_validator, so this will raise if the referenced tool slug is unknown.\n\n\nIn short: from_db here is simpler: it only converts the stored phase string to a Phase enum and lets Pydantic + validators do the rest.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#conceptual-pattern-across-all-three",
    "href": "classes_db.html#conceptual-pattern-across-all-three",
    "title": "Define Classes and create the SQLite database",
    "section": "Conceptual pattern across all three",
    "text": "Conceptual pattern across all three\n\nDB schema is “flattened”:\n\nEnums → strings.\nLists/tuples → JSON text.\nNested models → multiple columns.\n\nflatten_for_db does the forward conversion to DB‑friendly fields.\nfrom_db does the reverse: rehydrate Enums, nested Pydantic models, and collections from that DB representation, returning fully-typed domain models ready for use in the app.\n\nIf you want, I can also trace one concrete row (e.g. a Tool with multiple organization_system values) through flatten_for_db → SQLite row → from_db for a more step-by-step example.I’ll open infoflow/classdb.py, find the InformationItem, Tool, and Improvement Pydantic dataclasses, and then walk through how their from_db methods behave, including any differences between them.\nHere’s how from_db works for each of the three Pydantic models, based on classdb.py.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#tool.from_db",
    "href": "classes_db.html#tool.from_db",
    "title": "Define Classes and create the SQLite database",
    "section": "1. Tool.from_db",
    "text": "1. Tool.from_db\n@classmethod\ndef from_db(cls, db_record):\n    phase_quality = PhaseQualityData(\n        collect=PhaseQuality(db_record['collect_quality']),\n        retrieve=PhaseQuality(db_record['retrieve_quality']),\n        consume=PhaseQuality(db_record['consume_quality']),\n        extract=PhaseQuality(db_record['extract_quality']),\n        refine=PhaseQuality(db_record['refine_quality'])\n    )\n    org_systems = [OrganizationSystem(s) for s in json.loads(db_record['organization_system'])]\n    return cls(\n        id=db_record['id'],\n        name=db_record['name'],\n        description=db_record.get('description'),\n        organization_system=org_systems,\n        phase_quality=phase_quality,\n        collect=db_record['collect'],\n        retrieve=db_record['retrieve'],\n        consume=db_record['consume'],\n        extract=db_record['extract'],\n        refine=db_record['refine']\n    )\n\nInput: db_record is a row from the Tools table (e.g. a dict-like object from fastlite).\nRebuild phase_quality:\n\nDB stores each quality as a string ('na' | 'bad' | 'ok' | 'great').\nPhaseQualityData is reconstructed by wrapping each DB value with the PhaseQuality enum.\n\nRebuild organization_system:\n\nDB stores it as a JSON string representing a list of enum values, e.g. [\"tags\",\"folders\"].\njson.loads turns that into a Python list of strings.\nEach string is turned into an OrganizationSystem enum instance.\n\nInstantiate Tool:\n\nPass all the primitive fields straight from db_record.\nPass the reconstructed phase_quality and organization_system.\n\nSide-effect:\n\ninit registers the instance in Tool._instances keyed by slug.\n\n\nIn short: from_db converts DB‑friendly fields (JSON/string) back into enum-rich, structured Pydantic objects.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#informationitem.from_db-1",
    "href": "classes_db.html#informationitem.from_db-1",
    "title": "Define Classes and create the SQLite database",
    "section": "2. InformationItem.from_db",
    "text": "2. InformationItem.from_db\n@classmethod\ndef from_db(cls, db_record):\n    toolflow = PhaseToolflowData(\n        collect=cls._parse_toolflow(db_record['collect_toolflow']),\n        retrieve=cls._parse_toolflow(db_record['retrieve_toolflow']),\n        consume=cls._parse_toolflow(db_record['consume_toolflow']),\n        extract=cls._parse_toolflow(db_record['extract_toolflow']),\n        refine=cls._parse_toolflow(db_record['refine_toolflow'])\n    )\n    method = PhaseMethodData(\n        collect=db_record['collect_method'],\n        retrieve=db_record['retrieve_method'],\n        consume=db_record['consume_method'],\n        extract=db_record['extract_method'],\n        refine=db_record['refine_method']\n    )\n    info_type = InformationType(db_record['info_type'])\n    return cls(\n        id=db_record['id'],\n        name=db_record['name'],\n        info_type=info_type,\n        method=method,\n        toolflow=toolflow\n    )\nThe helper:\n@staticmethod\ndef _parse_toolflow(v):\n    if v is None: return None\n    if isinstance(v, str) and v.startswith('['): return json.loads(v)\n    return v\n\nInput: a row from InformationItems.\nRebuild toolflow:\n\nDB stores each *_toolflow as either:\n\nNULL/None,\na plain string (single tool),\nor a JSON-encoded list (multiple tools).\n\n_parse_toolflow:\n\nreturns None for None,\njson.loads if it looks like a JSON list (starts with '['),\notherwise leaves the string as‑is.\n\nThose values feed into PhaseToolflowData (which itself sanitizes names via validators).\n\nRebuild method:\n\nNote: DB stores method values as strings (\"manual\", \"automatic\", \"na\" or None).\nPhaseMethodData fields are annotated as Method | None, so Pydantic will convert those strings to Method enums automatically.\n\nRebuild info_type:\n\nDB stores info_type as its string value (e.g. \"book\").\nThis is wrapped into InformationType.\n\nInstantiate InformationItem:\n\nPass the reconstructed info_type, method, toolflow, plus id and name.\ninit adds the instance to InformationItem._instances.\n\n\nIn short: from_db reverses the flattening that turned nested structures (PhaseMethodData, PhaseToolflowData, InformationType) into many DB columns + JSON strings.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#improvement.from_db-1",
    "href": "classes_db.html#improvement.from_db-1",
    "title": "Define Classes and create the SQLite database",
    "section": "3. Improvement.from_db",
    "text": "3. Improvement.from_db\n@classmethod\ndef from_db(cls, db_record):\n    phase = Phase(db_record['phase'])\n    return cls(\n        id=db_record['id'],\n        title=db_record['title'],\n        what=db_record['what'],\n        why=db_record['why'],\n        prio=db_record['prio'],\n        tool=db_record['tool'],\n        phase=phase\n    )\n\nInput: a row from Improvements.\nRebuild phase:\n\nDB stores phase as a string (e.g. \"collect\").\nWrap in the Phase enum.\n\nInstantiate Improvement:\n\nAll other fields are passed through as-is.\ninit registers in Improvement._instances.\ntool will be validated against Tool.get_instances() by the field_validator, so this will raise if the referenced tool slug is unknown.\n\n\nIn short: from_db here is simpler: it only converts the stored phase string to a Phase enum and lets Pydantic + validators do the rest.",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#conceptual-pattern-across-all-three-1",
    "href": "classes_db.html#conceptual-pattern-across-all-three-1",
    "title": "Define Classes and create the SQLite database",
    "section": "Conceptual pattern across all three",
    "text": "Conceptual pattern across all three\n\nDB schema is “flattened”:\n\nEnums → strings.\nLists/tuples → JSON text.\nNested models → multiple columns.\n\nflatten_for_db does the forward conversion to DB‑friendly fields.\nfrom_db does the reverse: rehydrate Enums, nested Pydantic models, and collections from that DB representation, returning fully-typed domain models ready for use in the app.\n\nIf you want, I can also trace one concrete row (e.g. a Tool with multiple organization_system values) through flatten_for_db → SQLite row → from_db for a more step-by-step example.\n\nsource\n\nPhaseQualityData\n\n PhaseQualityData (collect:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   retrieve:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   consume:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   extract:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;,\n                   refine:__main__.PhaseQuality=&lt;PhaseQuality.NA: 'na'&gt;)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\n\nsource\n\n\nTool\n\n Tool (id:int|None=None, name:str, description:str|None=None,\n       organization_system:list[__main__.OrganizationSystem],\n       phase_quality:__main__.PhaseQualityData, collect:str|None=None,\n       retrieve:str|None=None, consume:str|None=None,\n       extract:str|None=None, refine:str|None=None)\n\nPydantic dataclass for tools. This Pydantic dataclass has several methods for converting to and from a SQLite database. This is needed because SQLite doesn’t support all used data types. !IMPORTANT: be sure to add or change the appropriate methods when adding or changing fields!\n\nsource\n\n\nPhaseMethodData\n\n PhaseMethodData (collect:__main__.Method|None=None,\n                  retrieve:__main__.Method|None=None,\n                  consume:__main__.Method|None=None,\n                  extract:__main__.Method|None=None,\n                  refine:__main__.Method|None=None)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\nSince Pydantic v2 Pydantic coerces sequences to tuples with a type of tuple[str, ...] Pydantic will accept a list[str, ...] as a valid input. Therefore we must include both tuple and list as a valid instance int the staticmethod _san. Else the validation will return None if a list is passed which is bad. It should return a TypeError to inform the user to use a tuple or it should just return the values as a tuple. The function _san now returns a tuple of strings if a list is passed.\n\nsource\n\n\nPhaseToolflowData\n\n PhaseToolflowData (collect:Union[str,tuple[str,...],NoneType]=None,\n                    retrieve:Union[str,tuple[str,...],NoneType]=None,\n                    consume:Union[str,tuple[str,...],NoneType]=None,\n                    extract:Union[str,tuple[str,...],NoneType]=None,\n                    refine:Union[str,tuple[str,...],NoneType]=None)\n\n*!!! abstract “Usage Documentation” Models\nA base class for creating Pydantic models.\nAttributes: class_vars: The names of the class variables defined on the model. private_attributes: Metadata about the private attributes of the model. signature: The synthesized __init__ [Signature][inspect.Signature] of the model.\n__pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n__pydantic_core_schema__: The core schema of the model.\n__pydantic_custom_init__: Whether the model has a custom `__init__` function.\n__pydantic_decorators__: Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n__pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n__pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n__pydantic_post_init__: The name of the post-init method for the model, if defined.\n__pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n__pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n__pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n__pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n__pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n\n__pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n    is set to `'allow'`.\n__pydantic_fields_set__: The names of fields explicitly set during instantiation.\n__pydantic_private__: Values of private attributes set on the model instance.*\nExample of creating an instance from PhaseToolflowData with all possible types of input: str, list[str], tuple[str] and just skipping an entry to return None.\n\nPhaseToolflowData(collect=[\"Reader\", \"Recall\"], retrieve=\"Recall\", refine=(\"Obsidian\", \"Recall\"))\n\nPhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume=None, extract=None, refine=('obsidian', 'recall'))\n\n\n\nsource\n\n\nInformationItem\n\n InformationItem (id:int|None=None, name:str,\n                  info_type:__main__.InformationType,\n                  method:__main__.PhaseMethodData,\n                  toolflow:__main__.PhaseToolflowData)\n\nPydantic dataclass for information items. This Pydantic dataclass has several methods for converting to and from a SQLite database. This is needed because SQLite doesn’t support all used data types. !IMPORTANT: be sure to add or change the appropriate methods when adding or changing fields!\n\nsource\n\n\nImprovement\n\n Improvement (id:int|None=None, name:str, what:str, why:str, how:str,\n              prio:int, tool:str, phase:__main__.Phase)\n\nPydantic dataclass for improvements. This Pydantic dataclass has several methods for converting to and from a SQLite database. This is needed because SQLite doesn’t support all used data types. !IMPORTANT: be sure to add or change the appropriate methods when adding or changing fields!\nTest creating instances\n\ndef test_phase_quality_data():\n    pqd = PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT)\n    test_eq(pqd.collect, PhaseQuality.GREAT)\n    test_eq(pqd.retrieve, PhaseQuality.BAD)\n\ndef test_tool_creation():\n    tool = Tool(id=12, name=\"TestTool\", organization_system=[OrganizationSystem.TAGS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n    test_eq(tool.name, \"TestTool\")\n    test_eq(tool.slug, \"testtool\")\n    test_eq(tool.phase_quality.collect, PhaseQuality.GREAT)\n    return tool\n\ndef test_tool_flatten():\n    tool = Tool(id=12, name=\"TestTool\", organization_system=[OrganizationSystem.TAGS, OrganizationSystem.FOLDERS], phase_quality=PhaseQualityData(collect=PhaseQuality.GREAT, retrieve=PhaseQuality.BAD, consume=PhaseQuality.OK, extract=PhaseQuality.NA, refine=PhaseQuality.GREAT))\n    flat = tool.flatten_for_db()\n    test_eq(flat['collect_quality'], 'great')\n    test_eq(flat['retrieve_quality'], 'bad')\n    test_eq(flat['name'], 'TestTool')\n\ndef test_information_item():\n    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n    tools = PhaseToolflowData(collect=\"Reader\", retrieve=(\"Recall\", \"Reader\"), consume=None, extract=None, refine=None)\n    item = InformationItem(id=16, name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n    test_eq(item.method.collect, Method.MANUAL)\n    test_eq(item.toolflow.collect, \"reader\")\n    test_eq(item.toolflow.retrieve, (\"recall\", \"reader\"))\n    return item\n\ndef test_information_item_flatten():\n    methods = PhaseMethodData(collect=Method.MANUAL, retrieve=None, consume=None, extract=None, refine=None)\n    tools = PhaseToolflowData(collect=(\"Reader\", \"Recall\"), retrieve=\"Recall\", consume=None, extract=None, refine=None)\n    item = InformationItem(id=16,name=\"Test Article\", info_type=InformationType.WEB_ARTICLE, method=methods, toolflow=tools)\n    flat = item.flatten_for_db()\n    test_eq(flat['collect_method'], 'manual')\n    test_eq(flat['retrieve_method'], None)\n    test_eq(flat['collect_toolflow'], '[\"reader\", \"recall\"]')\n    test_eq(flat['retrieve_toolflow'], 'recall')\n\ndef test_improvement():\n    imp = Improvement(id=18, name=\"Fix Search\", what=\"Better search in Reader\", why=\"Current search is bad\", how=\"By thinking for yoursel\", prio=1, tool=\"testtool\", phase=Phase.RETRIEVE)\n    test_eq(imp.name, \"Fix Search\")\n    test_eq(imp.phase, Phase.RETRIEVE)\n    test_eq(imp.flatten_for_db()['phase'], 'retrieve')\n    return imp\n\n\nOrganizationSystem(\"tags\")\n\n&lt;OrganizationSystem.TAGS: 'tags'&gt;\n\n\n\nOrganizationSystem.FOLDERS\n\n&lt;OrganizationSystem.FOLDERS: 'folders'&gt;\n\n\n\ntest_phase_quality_data()\ntest_tool_creation()\ntest_tool_flatten()\ntest_information_item()\ntest_information_item_flatten()\ntest_improvement()\n\nImprovement(id=18, name='Fix Search', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search')",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "classes_db.html#sqlite-database",
    "href": "classes_db.html#sqlite-database",
    "title": "Define Classes and create the SQLite database",
    "section": "SQLite database",
    "text": "SQLite database\n\nCreate and connect\nConnect to the database in the main.py. We should also enable foreign key constraints. These are disabled by default in Sqlite.\nFor testing purposes in this module we will use db = database(\":memory:\") to create an in-memory database.\n\nsource\n\n\ncreate_db\n\n create_db (loc:str='../data/infoflow.db')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nloc\nstr\n../data/infoflow.db\nLocation of the SQLite database\n\n\nReturns\nDatabase\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can add foreign key constraints to the tables using the transform method from sqlite_utils.\ninf_tbl.transform(add_foreign_keys=[(\"&lt;field_name&gt;\", \"&lt;table_name_to_connect&gt;\", \"&lt;field_name_in_table_to_connect&gt;\")])\n\n\nBut for now we won’t use foreign key constraints.\nWe can create the tables using the function create_tables_from_pydantic but we won’t be using it. The tables will be created automatically when we insert the first item for each table.\n\nsource\n\n\ncreate_tables_from_pydantic\n\n create_tables_from_pydantic (db:apswutils.db.Database,\n                              classes:List[pydantic.main.BaseModel])\n\nTests and usage examples\n\ndb = create_db(\":memory:\")\n\n\ncreate_tables_from_pydantic(db, [Tool, InformationItem, Improvement])\n\n\ndb.t\n\nimprovements, information_items, tools\n\n\n\ndb.t.improvements.c\n\nhow, id, name, phase, prio, slug, tool, what, why\n\n\nTesting of manipulating database by adding a “something” field to the Improvement dataclass.\n\nImprovement.get_instances()\n\n{'fix_search': Improvement(id=18, name='Fix Search', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search')}\n\n\n\ndb.t.improvements.insert(test_improvement().flatten_for_db())\n\n{'id': 18,\n 'name': 'Fix Search',\n 'what': 'Better search in Reader',\n 'why': 'Current search is bad',\n 'how': 'By thinking for yoursel',\n 'prio': 1,\n 'tool': 'testtool',\n 'phase': 'retrieve',\n 'slug': 'fix_search'}\n\n\n\nImprovement.get_instances()\n\n{'fix_search': Improvement(id=18, name='Fix Search', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search')}\n\n\n\nbefore_cols = [c.name for c in L(db.t.improvements.c)]\n\n\nclass Improvement(SluggedModel):\n    \"\"\"Pydantic dataclass for improvements. This Pydantic dataclass has several methods for converting to and from a \n    SQLite database. This is needed because SQLite doesn't support all used data types.\n    !IMPORTANT: be sure to add or change the appropriate methods when adding or changing fields!\"\"\"\n    id: int | None = Field(default=None, description=\"ID of the improvement, is automatically created when inserted in db.\")\n    name: str = Field(..., description=\"Title of the improvement\")\n    what: str = Field(..., description=\"What needs to be improved\")\n    why: str = Field(..., description=\"Why is this improvement needed\")\n    how: str = Field(..., description=\"Some ideas how to build this improvement\")\n    prio: int = Field(..., description=\"Priority of the improvement. Lowest number is highest priority\")\n    tool: str = Field(..., description=\"slug of the Tool that needs improvement\")\n    something: str = Field(..., description=\"Something\")\n    phase: Phase = Field(..., description=\"Phase that needs improvement\")\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        type(self)._instances[self.slug] = self\n\n    @classmethod\n    def get_instances(cls) -&gt; Dict[str, \"Improvement\"]:\n        return cls._instances\n\n    _instances: ClassVar[Dict[str, \"Improvement\"]] = {}\n\n    def flatten_for_db(self):\n        return self.model_dump()\n\n    @classmethod\n    def get_db_schema(cls):\n        \"\"\"Returns a dataclass with SQLite-compatible field types.\"\"\"\n        @dataclass\n        class Improvements: # Class name is used as table name automatically\n            id: int\n            name: str\n            what: str\n            why: str\n            how: str\n            prio: int\n            tool: str\n            something: str\n            phase: str\n            slug: str\n        return Improvements\n\n    @field_serializer('phase')\n    def db_serialize(self, v):\n        return v.value\n    \n    @field_validator('tool')\n    def validate_tool_names(cls, v):\n        valid_tools = Tool.get_instances().keys()\n        if v not in valid_tools: raise ValueError(f\"Tool '{v}' does not exist\")\n        return v\n    \n    @classmethod\n    def from_db(cls, db_record):\n        phase = Phase(db_record['phase'])\n        return cls(id=db_record['id'], name=db_record['name'], what=db_record['what'], why=db_record['why'], prio=db_record['prio'], tool=db_record['tool'], phase=phase)\n\n\ndef test_improvement_newschema():\n    imp = Improvement(id=20, name=\"Fix Search again\", what=\"Better search in Reader\", why=\"Current search is bad\", how=\"By thinking for yoursel\", prio=1, tool=\"testtool\", something=\"omnious\", phase=Phase.RETRIEVE)\n    test_eq(imp.name, \"Fix Search again\")\n    test_eq(imp.phase, Phase.RETRIEVE)\n    test_eq(imp.flatten_for_db()['phase'], 'retrieve')\n    return imp\ntest_improvement_newschema()\nImprovement.get_instances()\n\n{'fix_search_again': Improvement(id=20, name='Fix Search again', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', something='omnious', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search_again')}\n\n\n\ncreate_tables_from_pydantic(db, [Improvement])\n\n\nafter_cols = [c.name for c in L(db.t.improvements.c)]\n\n\nif before_cols == after_cols:\n    raise ValueError(\"Improvements table conversion does not work correctly.\")\n\nCheck if data is still in database\n\ndb.t.improvements['18'].name\n\n'Fix Search'\n\n\n\ntest_eq(db.t.improvements['18'].name, \"Fix Search\")\n\n\nAdd data to the database\nAdd the created instances to the SQLite tables\n\nTool.get_instances()\n\n{'testtool': Tool(id=12, name='TestTool', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;, &lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='testtool')}\n\n\n\nInformationItem.get_instances()\n\n{'test_article': InformationItem(id=16, name='Test Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume=None, extract=None, refine=None), slug='test_article')}\n\n\n\nImprovement.get_instances()\n\n{'fix_search_again': Improvement(id=20, name='Fix Search again', what='Better search in Reader', why='Current search is bad', how='By thinking for yoursel', prio=1, tool='testtool', something='omnious', phase=&lt;Phase.RETRIEVE: 'retrieve'&gt;, slug='fix_search_again')}\n\n\nAdd a single instance to the SQLite table\n\ntst = {'name': 'NeoReader', 'collect': None, 'retrieve': None, 'consume': None, 'extract': None, 'refine': None, 'slug': 'neoreader', 'organization_system': '[\"folders\"]', 'collect_quality': 'ok', 'retrieve_quality': 'bad', 'consume_quality': 'great', 'extract_quality': 'na', 'refine_quality': 'na'}\n\n\ndb.t.tools.insert(tst)\n\n{'id': 1,\n 'name': 'NeoReader',\n 'description': None,\n 'collect': None,\n 'retrieve': None,\n 'consume': None,\n 'extract': None,\n 'refine': None,\n 'slug': 'neoreader',\n 'organization_system': '[\"folders\"]',\n 'collect_quality': 'ok',\n 'retrieve_quality': 'bad',\n 'consume_quality': 'great',\n 'extract_quality': 'na',\n 'refine_quality': 'na'}\n\n\n\ntst2 = {'id': 1, 'name': 'NeoReader', 'collect': \"hiers staat nu wat\", 'retrieve': None, 'consume': None, 'extract': None, 'refine': None, 'slug': 'neoreader', 'organization_system': '[\"folders\"]', 'collect_quality': 'ok', 'retrieve_quality': 'bad', 'consume_quality': 'great', 'extract_quality': 'na', 'refine_quality': 'na'}\n\n\ndb.t.tools.update(tst2)\n\n{'id': 1,\n 'name': 'NeoReader',\n 'description': None,\n 'collect': 'hiers staat nu wat',\n 'retrieve': None,\n 'consume': None,\n 'extract': None,\n 'refine': None,\n 'slug': 'neoreader',\n 'organization_system': '[\"folders\"]',\n 'collect_quality': 'ok',\n 'retrieve_quality': 'bad',\n 'consume_quality': 'great',\n 'extract_quality': 'na',\n 'refine_quality': 'na'}\n\n\n\nImprovement.get_instances()['fix_search_again'].flatten_for_db()\n\n{'id': 20,\n 'name': 'Fix Search again',\n 'what': 'Better search in Reader',\n 'why': 'Current search is bad',\n 'how': 'By thinking for yoursel',\n 'prio': 1,\n 'tool': 'testtool',\n 'something': 'omnious',\n 'phase': 'retrieve',\n 'slug': 'fix_search_again'}\n\n\n\ndb.t.improvements.c\n\nhow, id, name, phase, prio, slug, something, tool, what, why\n\n\n\ndb.t.improvements.insert(Improvement.get_instances()['fix_search_again'].flatten_for_db())\ndb.t.information_items.insert(InformationItem.get_instances()['test_article'].flatten_for_db())\n\n{'id': 16,\n 'name': 'Test Article',\n 'info_type': 'web_article',\n 'slug': 'test_article',\n 'collect_method': 'manual',\n 'retrieve_method': None,\n 'consume_method': None,\n 'extract_method': None,\n 'refine_method': None,\n 'collect_toolflow': '[\"reader\", \"recall\"]',\n 'retrieve_toolflow': 'recall',\n 'consume_toolflow': None,\n 'extract_toolflow': None,\n 'refine_toolflow': None}\n\n\n\n[r for r in db.t.information_items.rows_where()]\n\n[{'id': 16,\n  'name': 'Test Article',\n  'info_type': 'web_article',\n  'slug': 'test_article',\n  'collect_method': 'manual',\n  'retrieve_method': None,\n  'consume_method': None,\n  'extract_method': None,\n  'refine_method': None,\n  'collect_toolflow': '[\"reader\", \"recall\"]',\n  'retrieve_toolflow': 'recall',\n  'consume_toolflow': None,\n  'extract_toolflow': None,\n  'refine_toolflow': None}]\n\n\nAdd multiple instances to the SQLite table\n\ndb.t.tools.insert_all([t.flatten_for_db() for t in Tool.get_instances().values()])\n\n&lt;Table tools (id, name, description, collect, retrieve, consume, extract, refine, slug, organization_system, collect_quality, retrieve_quality, consume_quality, extract_quality, refine_quality)&gt;\n\n\n\n[t.flatten_for_db() for t in Tool.get_instances().values()]\n\n[{'id': 12,\n  'name': 'TestTool',\n  'description': None,\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\n[r for r in db.t.tools.rows]\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'description': None,\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'description': None,\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\n\nRetrieve data from the database\nNow retrieve the info from the database as intances from the Pydantic Dataclass using the MiniDataAPI from answer.ai.\n\ntype(db.t.tools)\n\napswutils.db.Table\n\n\n\ndb.t.tools()\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'description': None,\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'description': None,\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\ntool = Tool.from_db(db.t.tools()[0])\ntool\n\nTool(id=1, name='NeoReader', description=None, organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect='hiers staat nu wat', retrieve=None, consume=None, extract=None, refine=None, slug='neoreader')\n\n\n\ndb.t.tools()\n\n[{'id': 1,\n  'name': 'NeoReader',\n  'description': None,\n  'collect': 'hiers staat nu wat',\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'neoreader',\n  'organization_system': '[\"folders\"]',\n  'collect_quality': 'ok',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'great',\n  'extract_quality': 'na',\n  'refine_quality': 'na'},\n {'id': 12,\n  'name': 'TestTool',\n  'description': None,\n  'collect': None,\n  'retrieve': None,\n  'consume': None,\n  'extract': None,\n  'refine': None,\n  'slug': 'testtool',\n  'organization_system': '[\"tags\", \"folders\"]',\n  'collect_quality': 'great',\n  'retrieve_quality': 'bad',\n  'consume_quality': 'ok',\n  'extract_quality': 'na',\n  'refine_quality': 'great'}]\n\n\n\nsource\n\n\n\ndict_from_db\n\n dict_from_db (db_table:apswutils.db.Table,\n               class_table:pydantic.main.BaseModel)\n\nConverts a database table to a dictionary of pydantic models.\n\ntools_dict = dict_from_db(db.t.tools, Tool)\nitem_dict = dict_from_db(db.t.information_items, InformationItem)\n\n\ngetattr(db.t.improvements()[0], 'tool')\n\n'testtool'\n\n\n\ntools_dict\n\n{'neoreader': Tool(id=1, name='NeoReader', description=None, organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect='hiers staat nu wat', retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'testtool': Tool(id=12, name='TestTool', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;, &lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='testtool')}",
    "crumbs": [
      "Define Classes and create the SQLite database"
    ]
  },
  {
    "objectID": "create_webapp.html",
    "href": "create_webapp.html",
    "title": "Create the webapplication logic and visualisations",
    "section": "",
    "text": "The web-application will show on the main page the information flow as created by the create_combined_infoflow_viz from the infoflow.viz module. This function returns a graphviz.graphs.Digraph object. We turn this object into a SVG string which we can then modify to create clickable nodes. To make this possible we need several steps:\n\nCreate the infoflow graph, see Create the vizualisation\nConvert the graph to an SVG string, see Create the vizualisation\nCreate a dictionary from all the nodes in the graph\nUse that dictionary to alter the SVG string to create clickable nodes\nCreate the main page from the web-application that shows the information flow as an SVG image.\nCreate a function to make a webpage for every element in the infoflow.\n\n\nAd. 4.\nWe could also create this dictionary from the instances we made from all the elements in our infoflow. The same instances that are use to create the graph in the first place. But I choose to create the dictionary from the SVG-string from the Digraph object, becaust then I will be able to use that function to create clickable SVG images from other sources as well.",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#stucture-of-the-web-application",
    "href": "create_webapp.html#stucture-of-the-web-application",
    "title": "Create the webapplication logic and visualisations",
    "section": "",
    "text": "The web-application will show on the main page the information flow as created by the create_combined_infoflow_viz from the infoflow.viz module. This function returns a graphviz.graphs.Digraph object. We turn this object into a SVG string which we can then modify to create clickable nodes. To make this possible we need several steps:\n\nCreate the infoflow graph, see Create the vizualisation\nConvert the graph to an SVG string, see Create the vizualisation\nCreate a dictionary from all the nodes in the graph\nUse that dictionary to alter the SVG string to create clickable nodes\nCreate the main page from the web-application that shows the information flow as an SVG image.\nCreate a function to make a webpage for every element in the infoflow.\n\n\nAd. 4.\nWe could also create this dictionary from the instances we made from all the elements in our infoflow. The same instances that are use to create the graph in the first place. But I choose to create the dictionary from the SVG-string from the Digraph object, becaust then I will be able to use that function to create clickable SVG images from other sources as well.",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#background-information-on-building-the-clickable-information-flow-visualisation-in-a-fasthtml-web-application",
    "href": "create_webapp.html#background-information-on-building-the-clickable-information-flow-visualisation-in-a-fasthtml-web-application",
    "title": "Create the webapplication logic and visualisations",
    "section": "Background information on building the clickable information flow visualisation in a FastHTML web-application",
    "text": "Background information on building the clickable information flow visualisation in a FastHTML web-application\n\nHow to visualize a SVG string in a webapp\nUse NotStr() to prevent HTML escaping of the SVG string.\n\nsvg_sample = \"\"\"&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\\n&lt;!-- Generated by graphviz version 2.43.0 (0)\\n --&gt;\\n&lt;!-- Title: %3 Pages: 1 --&gt;\\n&lt;svg width=\"226pt\" height=\"534pt\"\\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\\n&lt;title&gt;%3&lt;/title&gt;\\n&lt;polygon fill=\"transparent\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\\n&lt;!-- neoreader_collect --&gt;\\n&lt;g id=\"node1\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_collect&lt;/title&gt;\\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve --&gt;\\n&lt;g id=\"node2\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\\n&lt;g id=\"edge2\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume --&gt;\\n&lt;g id=\"node3\" class=\"node\"&gt;\\n&lt;title&gt;neoreader_consume&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\\n&lt;g id=\"edge3\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract --&gt;\\n&lt;g id=\"node4\" class=\"node\"&gt;\\n&lt;title&gt;readwise_extract&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\\n&lt;g id=\"edge4\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- obsidian_refine --&gt;\\n&lt;g id=\"node5\" class=\"node\"&gt;\\n&lt;title&gt;obsidian_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\\n&lt;g id=\"edge5\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- recall_refine --&gt;\\n&lt;g id=\"node6\" class=\"node\"&gt;\\n&lt;title&gt;recall_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\\n&lt;g id=\"edge6\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document --&gt;\\n&lt;g id=\"node7\" class=\"node\"&gt;\\n&lt;title&gt;source_document&lt;/title&gt;\\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\\n&lt;g id=\"edge1\" class=\"edge\"&gt;\\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\\n&lt;/g&gt;\\n&lt;/g&gt;\\n&lt;/svg&gt;\\n\"\"\"\n\n\nprint(svg_sample)\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;!-- Generated by graphviz version 2.43.0 (0)\n --&gt;\n&lt;!-- Title: %3 Pages: 1 --&gt;\n&lt;svg width=\"226pt\" height=\"534pt\"\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\n&lt;title&gt;%3&lt;/title&gt;\n&lt;polygon fill=\"transparent\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\n&lt;!-- neoreader_collect --&gt;\n&lt;g id=\"node1\" class=\"node\"&gt;\n&lt;title&gt;neoreader_collect&lt;/title&gt;\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_retrieve --&gt;\n&lt;g id=\"node2\" class=\"node\"&gt;\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\n&lt;g id=\"edge2\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_consume --&gt;\n&lt;g id=\"node3\" class=\"node\"&gt;\n&lt;title&gt;neoreader_consume&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\n&lt;g id=\"edge3\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract --&gt;\n&lt;g id=\"node4\" class=\"node\"&gt;\n&lt;title&gt;readwise_extract&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\n&lt;g id=\"edge4\" class=\"edge\"&gt;\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\n&lt;/g&gt;\n&lt;!-- obsidian_refine --&gt;\n&lt;g id=\"node5\" class=\"node\"&gt;\n&lt;title&gt;obsidian_refine&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\n&lt;g id=\"edge5\" class=\"edge\"&gt;\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\n&lt;/g&gt;\n&lt;!-- recall_refine --&gt;\n&lt;g id=\"node6\" class=\"node\"&gt;\n&lt;title&gt;recall_refine&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\n&lt;g id=\"edge6\" class=\"edge\"&gt;\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\n&lt;/g&gt;\n&lt;!-- source_document --&gt;\n&lt;g id=\"node7\" class=\"node\"&gt;\n&lt;title&gt;source_document&lt;/title&gt;\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\n&lt;/g&gt;\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\n&lt;g id=\"edge1\" class=\"edge\"&gt;\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\n\n\n\n\nshow(Div(NotStr(svg_sample)))\n\n\n\n\n\n\n\n%3\n\n\n\nneoreader_collect\n\nNeoReader\n(collect)\n\n\n\nneoreader_retrieve\n\nNeoReader\n(retrieve)\n\n\n\nneoreader_collect-&gt;neoreader_retrieve\n\n\n\n\n\nneoreader_consume\n\nNeoReader\n(consume)\n\n\n\nneoreader_retrieve-&gt;neoreader_consume\n\n\n\n\n\nreadwise_extract\n\nReadwise\n(extract)\n\n\n\nneoreader_consume-&gt;readwise_extract\n\n\n\n\n\nobsidian_refine\n\nObsidian\n(refine)\n\n\n\nreadwise_extract-&gt;obsidian_refine\n\n\n\n\n\nrecall_refine\n\nRecall\n(refine)\n\n\n\nreadwise_extract-&gt;recall_refine\n\n\n\n\n\nsource_document\n\nDocument\n\n\n\nsource_document-&gt;neoreader_collect\n\n\n\n\n\n\n\n\n\n\nHow to make a node from the Digraph SVG-string clickable in FastHTML\n\nAdd onclick handlers with htmx.ajax calls to the  elements you want clickable\nInclude a target div (#content-area) where content will be swapped\nAdd a CSS style attribute so the pointer cursor changes to a hand when hovering over the node\n\nFor example you can add this to the  element of the node you want clickable:\nonclick=\"htmx.ajax('GET', '/recall-retrieve', {target: '#content-area', swap: 'outerHTML'})\"\nstyle=\"cursor: pointer;\"\nBut a more concise way is to add CSS styling to the FastHTML app that targets all nodes:\n.node { cursor: pointer; }\nThat is what we will be using in this application.\nBelow is an example of a SVG-string with a clickable node that shows a changing pointer cursor when hovering over it.\n\nsvg_sample_click = \"\"\"&lt;svg width=\"268pt\" height=\"338pt\" viewBox=\"0.00 0.00 267.84 338.16\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 334.16)\"&gt;\n&lt;polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-334.16 263.84,-334.16 263.84,4 -4,4\"/&gt;\n&lt;g id=\"node3\" class=\"node\" onclick=\"htmx.ajax('GET', '/recall-retrieve', {target: '#content-area', swap: 'outerHTML'})\" style=\"cursor: pointer;\"&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"198.09,-129.08 163.76,-160.13 95.08,-160.13 60.75,-129.08 95.08,-98.03 163.76,-98.03 198.09,-129.08\"/&gt;\n&lt;text text-anchor=\"middle\" x=\"129.42\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\n&lt;text text-anchor=\"middle\" x=\"129.42\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\"\"\"\n\nThe below example can’t be clicked, because it is not running on a webserver and the GET request will also fail, because the endpoint doesn’t exist yet. But it does show how the pointer changes.\n\nshow(Div(NotStr(svg_sample_click), id=\"content-area\"))\n\n\n\n\n\n\nRecall\n(retrieve)",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#create-a-dictionary-from-all-the-nodes-in-the-graph",
    "href": "create_webapp.html#create-a-dictionary-from-all-the-nodes-in-the-graph",
    "title": "Create the webapplication logic and visualisations",
    "section": "Create a dictionary from all the nodes in the graph",
    "text": "Create a dictionary from all the nodes in the graph\nThe SVG-string is an XML string. I considered several ways to parse XML string:\n\nBeautifulSoup\nminidom from xml.dom\nxml.etree.ElementTree\n\nI choose the latest because it is simpler than minidom from xml.dom. The main advantage of xml.dom is that it supports complete DOM operations. But that isn’t needed in this application. BeautifulSoup is propably more forgiving and versatile than xml.etree.ElementTree, but ElementTree is more than enough for this application and does not add another dependency.\nWe only look for node elements in the root of the XML string. We also skip the edge elements.\n\nsource\n\ndict_svgnodes\n\n dict_svgnodes (svg_str:str)\n\nExample usage of dict_svgnodes()\n\nnds_dict = dict_svgnodes(svg_sample)\npprint(nds_dict)\n\n{'neoreader_collect': {'class': 'node',\n                       'fill': 'lightblue',\n                       'id': 'node1',\n                       'stroke': 'black',\n                       'text': ['NeoReader', '(collect)']},\n 'neoreader_consume': {'class': 'node',\n                       'fill': 'lightgreen',\n                       'id': 'node3',\n                       'stroke': 'black',\n                       'text': ['NeoReader', '(consume)']},\n 'neoreader_retrieve': {'class': 'node',\n                        'fill': 'orange',\n                        'id': 'node2',\n                        'stroke': 'black',\n                        'text': ['NeoReader', '(retrieve)']},\n 'obsidian_refine': {'class': 'node',\n                     'fill': 'lightgreen',\n                     'id': 'node5',\n                     'stroke': 'black',\n                     'text': ['Obsidian', '(refine)']},\n 'readwise_extract': {'class': 'node',\n                      'fill': 'lightgreen',\n                      'id': 'node4',\n                      'stroke': 'black',\n                      'text': ['Readwise', '(extract)']},\n 'recall_refine': {'class': 'node',\n                   'fill': 'lightgreen',\n                   'id': 'node6',\n                   'stroke': 'black',\n                   'text': ['Recall', '(refine)']},\n 'source_document': {'class': 'node',\n                     'fill': 'none',\n                     'id': 'node7',\n                     'stroke': 'black',\n                     'text': ['Document']}}",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_webapp.html#create-clickable-nodes-in-the-svg-string",
    "href": "create_webapp.html#create-clickable-nodes-in-the-svg-string",
    "title": "Create the webapplication logic and visualisations",
    "section": "Create clickable nodes in the SVG string",
    "text": "Create clickable nodes in the SVG string\n\nsource\n\nadd_onclick_to_nodes\n\n add_onclick_to_nodes (svg_str:str)\n\nExample usage and test\n\nsvg_clickable = add_onclick_to_nodes(svg_sample)\n\n\nsvg_clickable\n\n'&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\\n&lt;!-- Generated by graphviz version 2.43.0 (0)\\n --&gt;\\n&lt;!-- Title: %3 Pages: 1 --&gt;\\n&lt;svg width=\"226pt\" height=\"534pt\"\\n viewBox=\"0.00 0.00 225.61 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\\n&lt;title&gt;%3&lt;/title&gt;\\n&lt;polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-530.27 221.61,-530.27 221.61,4 -4,4\"/&gt;\\n&lt;!-- neoreader_collect --&gt;\\n&lt;g id=\"node1\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_collect&lt;/title&gt;\\n&lt;polygon fill=\"lightblue\" stroke=\"black\" points=\"174.81,-423.24 143.44,-454.3 80.7,-454.3 49.33,-423.24 80.7,-392.19 143.44,-392.19 174.81,-423.24\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-427.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-412.04\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(collect)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve --&gt;\\n&lt;g id=\"node2\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;polygon fill=\"orange\" stroke=\"black\" points=\"174.81,-325.19 143.44,-356.24 80.7,-356.24 49.33,-325.19 80.7,-294.13 143.44,-294.13 174.81,-325.19\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-328.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-313.99\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(retrieve)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_collect&#45;&gt;neoreader_retrieve --&gt;\\n&lt;g id=\"edge2\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_collect&#45;&gt;neoreader_retrieve&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-392.11C112.07,-384.06 112.07,-375.21 112.07,-366.7\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-366.54 112.07,-356.54 108.57,-366.54 115.57,-366.54\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume --&gt;\\n&lt;g id=\"node3\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=neoreader\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;neoreader_consume&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"174.81,-227.13 143.44,-258.19 80.7,-258.19 49.33,-227.13 80.7,-196.08 143.44,-196.08 174.81,-227.13\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-230.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;NeoReader&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-215.93\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(consume)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_retrieve&#45;&gt;neoreader_consume --&gt;\\n&lt;g id=\"edge3\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_retrieve&#45;&gt;neoreader_consume&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-294.06C112.07,-286 112.07,-277.16 112.07,-268.64\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-268.49 112.07,-258.49 108.57,-268.49 115.57,-268.49\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract --&gt;\\n&lt;g id=\"node4\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=readwise\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;readwise_extract&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"168.25,-129.08 140.16,-160.13 83.98,-160.13 55.9,-129.08 83.98,-98.03 140.16,-98.03 168.25,-129.08\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-132.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Readwise&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-117.88\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(extract)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- neoreader_consume&#45;&gt;readwise_extract --&gt;\\n&lt;g id=\"edge4\" class=\"edge\"&gt;\\n&lt;title&gt;neoreader_consume&#45;&gt;readwise_extract&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-196.01C112.07,-187.95 112.07,-179.11 112.07,-170.59\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-170.43 112.07,-160.43 108.57,-170.43 115.57,-170.43\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- obsidian_refine --&gt;\\n&lt;g id=\"node5\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=obsidian\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;obsidian_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"106.22,-31.03 79.64,-62.08 26.5,-62.08 -0.07,-31.03 26.5,0.03 79.64,0.03 106.22,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Obsidian&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"53.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;obsidian_refine --&gt;\\n&lt;g id=\"edge5\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;obsidian_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M93.57,-97.95C88.34,-89.45 82.59,-80.08 77.09,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"79.93,-69.07 71.72,-62.38 73.97,-72.73 79.93,-69.07\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- recall_refine --&gt;\\n&lt;g id=\"node6\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/tool?slug=recall\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;recall_refine&lt;/title&gt;\\n&lt;polygon fill=\"lightgreen\" stroke=\"black\" points=\"217.65,-31.03 194.36,-62.08 147.78,-62.08 124.49,-31.03 147.78,0.03 194.36,0.03 217.65,-31.03\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-34.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Recall&lt;/text&gt;\\n&lt;text text-anchor=\"middle\" x=\"171.07\" y=\"-19.83\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;(refine)&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- readwise_extract&#45;&gt;recall_refine --&gt;\\n&lt;g id=\"edge6\" class=\"edge\"&gt;\\n&lt;title&gt;readwise_extract&#45;&gt;recall_refine&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M130.58,-97.95C135.8,-89.45 141.56,-80.08 147.05,-71.13\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"150.18,-72.73 152.43,-62.38 144.21,-69.07 150.18,-72.73\"/&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document --&gt;\\n&lt;g id=\"node7\" class=\"node\" onclick=\"htmx.ajax(\\'GET\\', \\'/resource?slug=document\\', {target: \\'#main-content\\', swap: \\'outerHTML\\'})\"&gt;\\n&lt;title&gt;source_document&lt;/title&gt;\\n&lt;polygon fill=\"none\" stroke=\"black\" points=\"149.07,-526.27 75.07,-526.27 75.07,-490.27 149.07,-490.27 149.07,-526.27\"/&gt;\\n&lt;text text-anchor=\"middle\" x=\"112.07\" y=\"-504.57\" font-family=\"Times,serif\" font-size=\"14.00\"&gt;Document&lt;/text&gt;\\n&lt;/g&gt;\\n&lt;!-- source_document&#45;&gt;neoreader_collect --&gt;\\n&lt;g id=\"edge1\" class=\"edge\"&gt;\\n&lt;title&gt;source_document&#45;&gt;neoreader_collect&lt;/title&gt;\\n&lt;path fill=\"none\" stroke=\"black\" d=\"M112.07,-490.07C112.07,-482.61 112.07,-473.54 112.07,-464.55\"/&gt;\\n&lt;polygon fill=\"black\" stroke=\"black\" points=\"115.57,-464.52 112.07,-454.52 108.57,-464.52 115.57,-464.52\"/&gt;\\n&lt;/g&gt;\\n&lt;/g&gt;\\n&lt;/svg&gt;\\n'\n\n\n\nshow(Div(NotStr(svg_clickable)))\n\n\n\n\n\n\n\n%3\n\n\n\nneoreader_collect\n\nNeoReader\n(collect)\n\n\n\nneoreader_retrieve\n\nNeoReader\n(retrieve)\n\n\n\nneoreader_collect-&gt;neoreader_retrieve\n\n\n\n\n\nneoreader_consume\n\nNeoReader\n(consume)\n\n\n\nneoreader_retrieve-&gt;neoreader_consume\n\n\n\n\n\nreadwise_extract\n\nReadwise\n(extract)\n\n\n\nneoreader_consume-&gt;readwise_extract\n\n\n\n\n\nobsidian_refine\n\nObsidian\n(refine)\n\n\n\nreadwise_extract-&gt;obsidian_refine\n\n\n\n\n\nrecall_refine\n\nRecall\n(refine)\n\n\n\nreadwise_extract-&gt;recall_refine\n\n\n\n\n\nsource_document\n\nDocument\n\n\n\nsource_document-&gt;neoreader_collect\n\n\n\n\n\n\n\n\n\ntest(svg_clickable, \"Reader\", operator.contains) # Check if the node name is in the svg string\ntest(svg_clickable, \"onclick\", operator.contains) # Check if the onclick attribute is in the svg string\ntest(svg_clickable, \"#main-content\", operator.contains) # Check if the id is in the svg string\ntest(svg_clickable, \"&lt;svg width=\", operator.contains) # Check if the svg tag is in the svg string\ntest(svg_clickable, \"xmlns\", operator.contains) # Check if the xmlns attribute is in the svg string",
    "crumbs": [
      "Create the webapplication logic and visualisations"
    ]
  },
  {
    "objectID": "create_instances.html",
    "href": "create_instances.html",
    "title": "Create Instances",
    "section": "",
    "text": "# TODO: Maybe we don't need this file. We can use the app to create instances and place those in the database.",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_instances.html#tools",
    "href": "create_instances.html#tools",
    "title": "Create Instances",
    "section": "Tools",
    "text": "Tools\nThe function tools_from_code can be used to create instances for every Tool available. The instances are hardcoded in the function. This function can be used to start a fresh database.\nThe function tools_from_db can be used to create instances for every Tool available in the database.\nIn both cases the function does not return anything. The available instances are tracked in the Tool class and can be retrieved as a list using the get_instances method on the Tool class.\nWe must start with creating instances for each Tool that we can use. This must be done before we can create instances for the InformationItem and Improvement classes, because both have fields that are validated against the field name in the Tool class.\n\nsource\n\ntools_from_code\n\n tools_from_code ()\n\nCreate all Tool instances as defined in the code.\nThe next stap is to define instances for each InformationItem we have.\n\ntools_from_code()\nTool.get_instances()\n\n{'reader': Tool(id=101, name='Reader', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', description=None, organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', description=None, organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', description=None, organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', description=None, organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', description=None, organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\n\nTool.get_instances()['reader']\n\nTool(id=101, name='Reader', description=None, organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader')",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_instances.html#informationitems",
    "href": "create_instances.html#informationitems",
    "title": "Create Instances",
    "section": "InformationItems",
    "text": "InformationItems\nJust as with the Tools we have two functions to create instances for every InformationItem. We can use the function informationitems_from_code to create instances for every InformationItem available from the definitions hardcoded in the function. This function can be used to start a fresh database. We can use the function informationitems_from_db to create instances for every InformationItem available in the database.\nThese functions don’t return anything. The available instances are tracked in the InformationItem class and can be retrieved as a list using the get_instances method on the InformationItem class.\n\nsource\n\ninformationitems_from_code\n\n informationitems_from_code ()\n\nCreate all InformationItem instances as defined in the code.\nCheck all the available tools and information items.\n\ninformationitems_from_code()\n\n\nInformationItem.get_instances()\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}",
    "crumbs": [
      "Create Instances"
    ]
  },
  {
    "objectID": "create_vizualisation.html",
    "href": "create_vizualisation.html",
    "title": "Create graphiz visualisation",
    "section": "",
    "text": "tools_from_code()\ninformationitems_from_code()\n\n\ntools_inst = Tool.get_instances()\nitems_inst = InformationItem.get_instances()\n\n\ntools_inst\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\n\nitems_inst\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}\n\n\n\ntest_eq(len(items_inst), 8)\ntest(tools_inst, \"reader\", operator.contains)",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#creating-some-instances-for-testing",
    "href": "create_vizualisation.html#creating-some-instances-for-testing",
    "title": "Create graphiz visualisation",
    "section": "",
    "text": "tools_from_code()\ninformationitems_from_code()\n\n\ntools_inst = Tool.get_instances()\nitems_inst = InformationItem.get_instances()\n\n\ntools_inst\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\n\nitems_inst\n\n{'web_article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article'),\n 'annotation': InformationItem(id=202, name='Annotation', info_type=&lt;InformationType.ANNOTATION: 'annotations&highlights'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve=None, consume=None, extract='readwise', refine=('recall', 'obsidian')), slug='annotation'),\n 'note': InformationItem(id=203, name='Note', info_type=&lt;InformationType.NOTE: 'note'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=None, retrieve='obsidian', consume='obsidian', extract='obsidian', refine='obsidian'), slug='note'),\n 'book': InformationItem(id=204, name='Book', info_type=&lt;InformationType.BOOK: 'book'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='librarything', retrieve='librarything', consume='neoreader', extract='readwise', refine='obsidian'), slug='book'),\n 'podcast': InformationItem(id=205, name='Podcast', info_type=&lt;InformationType.PODCAST: 'podcast'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='snipd', retrieve='snipd', consume='snipd', extract='readwise', refine='obsidian'), slug='podcast'),\n 'research_paper': InformationItem(id=206, name='Research Paper', info_type=&lt;InformationType.RESEARCH_PAPER: 'research_paper'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('recall', 'neoreader'), retrieve=('recall', 'neoreader'), consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='research_paper'),\n 'document': InformationItem(id=207, name='Document', info_type=&lt;InformationType.DOCUMENT: 'document'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='neoreader', retrieve='neoreader', consume='neoreader', extract='readwise', refine=('obsidian', 'recall')), slug='document'),\n 'youtube_video': InformationItem(id=208, name='YouTube Video', info_type=&lt;InformationType.YOUTUBE_VIDEO: 'youtube_video'&gt;, method=PhaseMethodData(collect=&lt;Method.AUTOMATIC: 'automatic'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect='youtube', retrieve='youtube', consume='youtube', extract='obsidian', refine='obsidian'), slug='youtube_video')}\n\n\n\ntest_eq(len(items_inst), 8)\ntest(tools_inst, \"reader\", operator.contains)",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#helper-functions",
    "href": "create_vizualisation.html#helper-functions",
    "title": "Create graphiz visualisation",
    "section": "Helper functions",
    "text": "Helper functions\nThe function get_items_for_tool filters all the instances of the class InformationItem based on which information items can be processed by the given tool.\n\nsource\n\nget_info_items_for_tool\n\n get_info_items_for_tool (tool_name:str,\n                          info_items:dict[infoflow.classdb.InformationItem\n                          ])\n\nFilters all the instances of the class InformationItem based on which information items can be processed by the given tool.\nTest the get_info_items_for_tool function.\n\nget_info_items_for_tool('reader', items_inst)\n\n{'Web Article': InformationItem(id=209, name='Web Article', info_type=&lt;InformationType.WEB_ARTICLE: 'web_article'&gt;, method=PhaseMethodData(collect=&lt;Method.MANUAL: 'manual'&gt;, retrieve=None, consume=None, extract=None, refine=None), toolflow=PhaseToolflowData(collect=('reader', 'recall'), retrieve='recall', consume='reader', extract=None, refine=None), slug='web_article')}",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "create_vizualisation.html#graphiz-visualisation",
    "href": "create_vizualisation.html#graphiz-visualisation",
    "title": "Create graphiz visualisation",
    "section": "Graphiz visualisation",
    "text": "Graphiz visualisation\nThe function to create the workflow visualisation for the given info_items and tools. This is done in two steps. First we use the function create_workflow_viz that functions as a wrapper around the build_graphiz_from_instances function.\nThe create_workflow_viz has two tasks:\n\nIt makes calling the build_graphiz_from_instances function easier by assuming we want to use all instances from the Tool and InformationItem classes. If we want to use a single instance, we can pass a single instance of Tool or InformationItem. If we want several, but not all, instances of Tool or InformationItem, we can pass a dict of instances.\nIt adds the option to filter the graph to be created on a single Tool-name. If the parameter tool_filter is used, the function calls the get_info_items_for_tool function and filters the needed InformationItem instances based on that tool. This way only those parts of the graph will be drawn that we want to see.\n\n\nsource\n\nbuild_graphiz_from_intances\n\n build_graphiz_from_intances (info_items, tools)\n\nCreate a graphviz visualisation using the updated dataclasses for InformationItem and Tool. Produces the same layout as build_graphiz_from_instances.\n\nsource\n\n\ncreate_workflow_viz\n\n create_workflow_viz (items:infoflow.classdb.InformationItem|dict[str,info\n                      flow.classdb.InformationItem], tools:infoflow.classd\n                      b.Tool|dict[str,infoflow.classdb.Tool],\n                      tool_filter:None|str=None)\n\nCreate workflow visualization with flexible filtering options.\n\nTool.get_instances()\n\n{'reader': Tool(id=101, name='Reader', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='reader'),\n 'recall': Tool(id=102, name='Recall', organization_system=[&lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.GREAT: 'great'&gt;, retrieve=&lt;PhaseQuality.GREAT: 'great'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='recall'),\n 'readwise': Tool(id=103, name='Readwise', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.OK: 'ok'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='readwise'),\n 'obsidian': Tool(id=104, name='Obsidian', organization_system=[&lt;OrganizationSystem.JOHNNY_DECIMAL: 'johnny_decimal'&gt;, &lt;OrganizationSystem.LINKS: 'links'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.NA: 'na'&gt;, retrieve=&lt;PhaseQuality.OK: 'ok'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.GREAT: 'great'&gt;, refine=&lt;PhaseQuality.GREAT: 'great'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='obsidian'),\n 'librarything': Tool(id=105, name='LibraryThing', organization_system=[&lt;OrganizationSystem.TAGS: 'tags'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.NA: 'na'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='librarything'),\n 'snipd': Tool(id=106, name='Snipd', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='snipd'),\n 'neoreader': Tool(id=107, name='NeoReader', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.GREAT: 'great'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='neoreader'),\n 'youtube': Tool(id=108, name='YouTube', organization_system=[&lt;OrganizationSystem.FOLDERS: 'folders'&gt;], phase_quality=PhaseQualityData(collect=&lt;PhaseQuality.OK: 'ok'&gt;, retrieve=&lt;PhaseQuality.BAD: 'bad'&gt;, consume=&lt;PhaseQuality.OK: 'ok'&gt;, extract=&lt;PhaseQuality.NA: 'na'&gt;, refine=&lt;PhaseQuality.NA: 'na'&gt;), collect=None, retrieve=None, consume=None, extract=None, refine=None, slug='youtube')}\n\n\nAn example for creating the actual visualisation for the given info_items and tools.\n\nviz = create_workflow_viz(items_inst, tools_inst)\ntype(viz)\n\ngraphviz.graphs.Digraph\n\n\n\nviz\n\n\n\n\n\n\n\n\n\nviz_document = create_workflow_viz(items_inst['research_paper'], tools_inst)\nviz_document\n\n\n\n\n\n\n\n\n\nviz_tool = create_workflow_viz(items_inst, tools_inst, tool_filter='neoreader')\nviz_tool\n\n\n\n\n\n\n\n\nTo get the SVG output, you can use the _repr_image_svg_xml method of the Digraph object. Below is an example showing the first 200 characters.\n\nprint(viz._repr_image_svg_xml()[:600])\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;!-- Generated by graphviz version 2.43.0 (0)\n --&gt;\n&lt;!-- Title: %3 Pages: 1 --&gt;\n&lt;svg width=\"956pt\" height=\"534pt\"\n viewBox=\"0.00 0.00 956.04 534.27\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\n&lt;g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530.27)\"&gt;\n&lt;title&gt;%3&lt;/title&gt;\n&lt;!-- reader_collect --&gt;\n&lt;g id=\"node1\" class=\"node\"&gt;\n&lt;title&gt;reader_collect&lt;/title&gt;\n&lt;polygon fill=\"lightgreen\" stroke=\"",
    "crumbs": [
      "Create graphiz visualisation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "infoflow",
    "section": "",
    "text": "I created this project because I want a personal knowledge management system to efficiently collect, organize, and retrieve information from various sources (books, articles, videos, podcasts, research papers, etc.). I usually can’t immediately consume the information I encounter. By building a clear workflow of actions and tools I use to solve the problem of having more interesting information than I can process. By creating a structured four-phase workflow (Collect, Retrieve, Consume, Refine) I aim to make it as easy and fast as possible to store items when I encounter them and later find relevant information when I need it based on my current interests or projects.\nI want to implement this as Python classes and visualize it with Graphviz because this approach provides flexibility to easily modify tools and processes, unlike static text or diagram-based approaches.\n\n\n\ncd {folder where you want to create the folder for this project}\ngit clone git@github.com:Hopsakee/infoflow.git\ncd infoflow\nuv sync\nuv run main.py\nThis starts a local server where the application will be run.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#user-guide",
    "href": "index.html#user-guide",
    "title": "infoflow",
    "section": "",
    "text": "I created this project because I want a personal knowledge management system to efficiently collect, organize, and retrieve information from various sources (books, articles, videos, podcasts, research papers, etc.). I usually can’t immediately consume the information I encounter. By building a clear workflow of actions and tools I use to solve the problem of having more interesting information than I can process. By creating a structured four-phase workflow (Collect, Retrieve, Consume, Refine) I aim to make it as easy and fast as possible to store items when I encounter them and later find relevant information when I need it based on my current interests or projects.\nI want to implement this as Python classes and visualize it with Graphviz because this approach provides flexibility to easily modify tools and processes, unlike static text or diagram-based approaches.\n\n\n\ncd {folder where you want to create the folder for this project}\ngit clone git@github.com:Hopsakee/infoflow.git\ncd infoflow\nuv sync\nuv run main.py\nThis starts a local server where the application will be run.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "infoflow",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall infoflow in Development mode\n# make sure infoflow package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to infoflow\n$ nbdev_prepare",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "infoflow",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/Hopsakee/infoflow.git\nor from conda\n$ conda install -c Hopsakee infoflow\nor from pypi\n$ pip install infoflow\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "infoflow"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "infoflow",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "infoflow"
    ]
  }
]